{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import pdb\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import itertools\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import argparse\n",
    "from torch import optim\n",
    "import time\n",
    "import os\n",
    "from bleu_score import BLEU_SCORE\n",
    "# from models_viet import EncoderRNN, AttentionDecoderRNN, DecoderRNN\n",
    "from load_dataset_viet import *\n",
    "# from define_training_viet import *\n",
    "import torchtext\n",
    "from torch.utils.data import BatchSampler\n",
    "from torch.utils.data import SequentialSampler\n",
    "from torch.utils.data import Sampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vietnamese(Dataset):\n",
    "    def __init__(self, df, val = False):\n",
    "        self.df = df\n",
    "        self.val = val\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        english = self.df.iloc[idx,:]['en_idized']\n",
    "        viet = self.df.iloc[idx,:]['vi_idized']\n",
    "        en_len = self.df.iloc[idx,:]['en_len']\n",
    "        vi_len = self.df.iloc[idx,:]['vi_len']\n",
    "        if self.val:\n",
    "            en_data = self.df.iloc[idx,:]['en_data'].lower()\n",
    "            return [viet,english,vi_len,en_len,en_data]\n",
    "        else:\n",
    "            return [viet,english,vi_len,en_len]\n",
    "    \n",
    "    \n",
    "def vocab_collate_func(batch):\n",
    "    MAX_LEN_EN = 48\n",
    "    MAX_LEN_VI = 48\n",
    "    en_data = []\n",
    "    vi_data = []\n",
    "    en_len = []\n",
    "    vi_len = []\n",
    "    for datum in batch:\n",
    "        en_len.append(datum[3])\n",
    "        vi_len.append(datum[2])\n",
    "    max_batch_length_en = max(en_len)\n",
    "    max_batch_length_vi = max(vi_len)\n",
    "    if max_batch_length_en < MAX_LEN_EN:\n",
    "        MAX_LEN_EN = max_batch_length_en\n",
    "    if max_batch_length_vi < MAX_LEN_VI:\n",
    "        MAX_LEN_VI = max_batch_length_vi\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        if datum[2]>MAX_LEN_VI:\n",
    "            padded_vec_s1 = np.array(datum[0])[:MAX_LEN_VI]\n",
    "        else:\n",
    "            padded_vec_s1 = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,MAX_LEN_VI - datum[2])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        if datum[3]>MAX_LEN_EN:\n",
    "            padded_vec_s2 = np.array(datum[1])[:MAX_LEN_EN]\n",
    "        else:\n",
    "            padded_vec_s2 = np.pad(np.array(datum[1]),\n",
    "                                pad_width=((0,MAX_LEN_EN - datum[3])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        en_data.append(padded_vec_s2)\n",
    "        vi_data.append(padded_vec_s1)\n",
    "    vi_data = np.array(vi_data)\n",
    "    en_data = np.array(en_data)\n",
    "    vi_len = np.array(vi_len)\n",
    "    en_len = np.array(en_len)\n",
    "    sorted_vi_len = np.argsort(-vi_len)\n",
    "    vi_data = vi_data[sorted_vi_len]\n",
    "    en_data = en_data[sorted_vi_len]\n",
    "    vi_len = vi_len[sorted_vi_len]\n",
    "    en_len = en_len[sorted_vi_len]\n",
    "#     print(en_len)\n",
    "    vi_len[vi_len>MAX_LEN_VI] = MAX_LEN_VI\n",
    "    en_len[en_len>MAX_LEN_EN] = MAX_LEN_EN\n",
    "        \n",
    "    return [torch.from_numpy(vi_data), torch.from_numpy(en_data),\n",
    "            torch.from_numpy(vi_len), torch.from_numpy(en_len)]\n",
    "\n",
    "def convert_idx_2_sent(tensor, lang_obj):\n",
    "    word_list = []\n",
    "    for i in tensor:\n",
    "        if i.item() not in set([PAD_IDX,EOS_token,SOS_token]):\n",
    "            word_list.append(lang_obj.index2word[i.item()])\n",
    "    return (' ').join(word_list)\n",
    "\n",
    "def convert_id_list_2_sent(list_idx, lang_obj):\n",
    "    word_list = []\n",
    "    if type(list_idx) == list:\n",
    "        for i in list_idx:\n",
    "            if i not in set([EOS_token]):\n",
    "                word_list.append(lang_obj.index2word[i])\n",
    "    else:\n",
    "        for i in list_idx:\n",
    "            if i.item() not in set([EOS_token,SOS_token,PAD_IDX]):\n",
    "                word_list.append(lang_obj.index2word[i.item()])\n",
    "    return (' ').join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_collate_func_val(batch):\n",
    "    return [torch.from_numpy(np.array(batch[0][0])).unsqueeze(0), torch.from_numpy(np.array(batch[0][1])).unsqueeze(0),\n",
    "            torch.from_numpy(np.array(batch[0][2])).unsqueeze(0), torch.from_numpy(np.array(batch[0][3])).unsqueeze(0),batch[0][4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_LEN = 48\n",
    "train,val,en_lang,vi_lang = train_val_load(48, \"\", '/scratch/ark576/machine_translation_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_sorted_batches(train, bs):\n",
    "    batch_samp_list = list(BatchSampler(SequentialSampler(train), bs, drop_last = False))\n",
    "    np.random.shuffle(batch_samp_list)\n",
    "    batch_samp_list_merged = list(itertools.chain(*batch_samp_list))\n",
    "    return train.iloc[batch_samp_list_merged,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sorted = train.sort_values('en_len', ascending = False)\n",
    "bs_dict = {'train':128,'validate':1, 'train_val':1}\n",
    "# train_used = train_sorted\n",
    "train_used = train.sample(10)\n",
    "# train_used = shuffle_sorted_batches(train_sorted,bs_dict['train'])\n",
    "collate_fn_dict = {'train':vocab_collate_func, 'validate':vocab_collate_func_val, 'train_val':vocab_collate_func_val}\n",
    "transformed_dataset = {'train': Vietnamese(train_used),\n",
    "                       'validate': Vietnamese(val, val = True),\n",
    "                       'train_val':Vietnamese(train.iloc[:50], val = True)\n",
    "                                               }\n",
    "\n",
    "dataloader = {x: DataLoader(transformed_dataset[x], batch_size=bs_dict[x], collate_fn=collate_fn_dict[x],\n",
    "                    shuffle=False, num_workers=0) for x in ['train', 'validate', 'train_val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sample = next(iter(dataloader['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 48])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 45])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48, 46, 25, 19, 15, 13, 10,  8,  8,  7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([45, 44, 27, 24, 14, 14, 11,  7,  5,  6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: so , 5,000 years after the invention of the wheel , we have a new wheel . and i will show you , in the next video -- can you start it , please ? -- that very heavy loads can be moved . EOS\n",
      "Viet: vì_thế 5000 năm sau khi bánh_xe được phát_minh , chúng_ta lại có một loại bánh_xe mới . tôi sẽ cho các bạn xem trong đoạn phim kế_tiếp - - - anh có_thể làm_ơn bật nó lên được không ? - - mà những vật rất nặng_nề có_thể di_chuyển\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: and the reason the british were coming was because they would not treat anybody with anything under age 16 , which means they were UKN them to an adult body , no matter what happened , even if they tested them well . EOS PAD\n",
      "Viet: lý_do người_ta gửi cháu sang đây là bên đó người_ta không điều_trị giới cho ai dưới 16 tuổi , có nghĩa họ cho việc đó chỉ được làm trong cơ_thể người_lớn , bất_chấp cái_gì đang xảy ra , cả khi xét_nghiệm cho thấy rõ_ràng . EOS PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: this UKN principle of UKN UKN would go on to be perfected with great success as one of the enduring principles of UKN systems everywhere . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Viet: nguyên_tắc độc_quyền khoá chặt khách_hàng sẽ tiếp_tục hoàn_hảo với thành_công lớn là một trong các nguyên_tắc bền_vững của hệ_thống cửa_sổ ở mọi nơi . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: and , you know , i was thinking , how could i take myself out of the picture for quite some time . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Viet: bạn biết đây , tôi đã suy_nghĩ , làm thế_nào để có_thể đứng ngoài_cuộc trong một thời_gian . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: you know , bees come in swarms and fish come in schools . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Viet: bạn biết đấy , ong đến theo đàn và cá đến theo đàn . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: that &apos;s why i call for the &quot; chief detail officer . &quot; EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Viet: đó là lý_do tôi thấy cần_thiết có_một \" giám_đốc điều_hành chi_tiết \" EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: and it is detectable not just in amino acids . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Viet: nó được tìm_thấy không chỉ ở amino acid . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: that &apos;s another great idea . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Viet: đó cũng là một ý_tưởng lớn . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: let me explain . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Viet: để tôi giải_thích cho các bạn . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: the hidden beauty of pollination EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Viet: vẻ đẹp tiềm_ẩn trong sự thụ_phấn EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    }
   ],
   "source": [
    "for t in zip(train_data_sample[1],train_data_sample[0]):\n",
    "    en_sent = []\n",
    "    vi_sent = []\n",
    "    for i in t[0]:\n",
    "        en_sent.append(en_lang.index2word[i.item()])\n",
    "    for i in t[1]:\n",
    "        vi_sent.append(vi_lang.index2word[i.item()])\n",
    "    print('English:',(' ').join(en_sent))\n",
    "    print('Viet:',(' ').join(vi_sent))\n",
    "    print('-*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13294"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16031"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OldEncoderRNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size,bi):\n",
    "#         super(OldEncoderRNN, self).__init__()\n",
    "#         self.bi=bi\n",
    "#         if self.bi:\n",
    "#             self.mul=2\n",
    "#         else:\n",
    "#             self.mul=1\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size,batch_first=True,bidirectional=self.bi)\n",
    "\n",
    "#     def forward(self, input, hidden):\n",
    "#         embedded = self.embedding(input)\n",
    "#         output = embedded\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "#         last_layer = output[:,-1,:self.hidden_size]\n",
    "#         first_layer = output[:,0,self.hidden_size:]\n",
    "#         hidden = torch.cat([first_layer,last_layer],dim=1).unsqueeze(0)\n",
    "#         return output, hidden\n",
    "\n",
    "#     def initHidden(self,bs):\n",
    "#         return torch.zeros(self.mul, bs, self.hidden_size).to(device)\n",
    "    \n",
    "    \n",
    "# class OldAttentionDecoderRNN(nn.Module):\n",
    "#     def __init__(self, hidden_size, output_size,bi, MAX_LEN,n_layers = 1, attention_type = None):\n",
    "#         super(OldAttentionDecoderRNN, self).__init__()\n",
    "#         self.mul=2\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "#         self.gru = nn.GRU(hidden_size*2 + hidden_size, hidden_size*2,batch_first=True, num_layers = n_layers)\n",
    "        \n",
    "#         self.attention_type = attention_type\n",
    "#         if self.attention_type is not None:\n",
    "#             self.attn = nn.Linear(self.hidden_size*2, self.hidden_size*2)\n",
    "#             self.attn_drop = nn.Dropout(p = 0.5)\n",
    "#         else:\n",
    "#             self.attn = nn.Linear(self.hidden_size * 2, MAX_LEN)\n",
    "        \n",
    "# #         self.attn_combine = nn.Linear(self.hidden_size * self.mul+self.hidden_size, self.hidden_size)\n",
    "        \n",
    "#         self.out = nn.Linear(self.mul*hidden_size, output_size)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input, hidden,encoder_outputs):\n",
    "#         bss = input.size(0)\n",
    "#         output = self.embedding(input)\n",
    "#         output = self.dropout(output)\n",
    "#         att_out = self.attn_drop(self.attn(hidden[-1])).unsqueeze(-1)\n",
    "#         if self.attention_type is not None:\n",
    "#             attn_wts = F.softmax(torch.bmm(encoder_outputs,att_out),dim = 1)\n",
    "#             attn_applied = torch.bmm(encoder_outputs.transpose(1,2),attn_wts).transpose(1,2)\n",
    "#         else:\n",
    "#             att_out = F.softmax(self.attn(cat),dim=1)\n",
    "#             attn_applied = torch.bmm(att_out,encoder_outputs)\n",
    "#         attn_cat = torch.cat((output, attn_applied), 2)\n",
    "#         output = F.relu(attn_cat)\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "#         output = self.out(output.squeeze(dim=1))\n",
    "#         output = self.softmax(output)\n",
    "\n",
    "#         return output, hidden\n",
    "\n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(self.mul, bs, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim, hidden_size,n_layers, rnn_type = 'lstm'):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = Embedding(input_size, embed_dim, PAD_IDX)\n",
    "        self.rnn_type =  rnn_type\n",
    "        self.dropout_in = nn.Dropout(p = 0.1)\n",
    "        self.n_layers = n_layers\n",
    "        if rnn_type == 'gru':\n",
    "            self.rnn = nn.GRU(embed_dim, hidden_size,batch_first=True,bidirectional=True, num_layers = self.n_layers, dropout = 0.2)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = LSTM(embed_dim, hidden_size, batch_first=True,bidirectional=True, num_layers = n_layers,dropout = 0.2)\n",
    "\n",
    "    def forward(self, input, src_len):\n",
    "        embedded = self.embedding(input)\n",
    "        bs = embedded.size(0)\n",
    "        output = self.dropout_in(embedded)\n",
    "#         print(\"encoded Input\", output.shape)\n",
    "#         output = torch.nn.utils.rnn.pack_padded_sequence(output, src_len, batch_first=True)\n",
    "        if self.rnn_type == 'gru':\n",
    "            hidden =  self.initHidden(bs)\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "#             output = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        elif self.rnn_type == 'lstm':\n",
    "            hidden, c = self.initHidden(bs)\n",
    "            packed_output = nn.utils.rnn.pack_padded_sequence(output, src_len.data.tolist(), batch_first = True)\n",
    "            packed_outs, (hiddden, c) = self.rnn(packed_output,(hidden, c))\n",
    "            output, _ = nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=PAD_IDX, batch_first = True)\n",
    "        hidden = hidden.view(self.n_layers, 2, bs, -1).transpose(1, 2).contiguous().view(self.n_layers, bs, -1)\n",
    "        c = c.view(self.n_layers, 2, bs, -1).transpose(1, 2).contiguous().view(self.n_layers, bs, -1)\n",
    "#         print(output.shape)\n",
    "#         print(hidden.shape)\n",
    "#         print(c.shape)\n",
    "#             output = torch.nn.utils.rnn.pad_packed_sequence(output,batch_first=True)\n",
    "#         print(hidden.shape)\n",
    "#         print(\"rnn output\", output.shape)\n",
    "#         print(\"rnn hidden\", hidden.shape)\n",
    "#         hidden = hidden.transpose(0,1).contiguous().view(bs,-1)\n",
    "#         hidden_1 = torch.tanh(self.linear1(hidden)).unsqueeze(0)\n",
    "# #         print(\"rnn hidden_1\", hidden_1.shape)\n",
    "#         hidden_2 = torch.tanh(self.linear2(hidden)).unsqueeze(0)\n",
    "# #         print(\"rnn hidden_2\", hidden_2.shape)\n",
    "#         hidden = torch.cat([hidden_1,hidden_2],dim = 0)\n",
    "#         print(\"rnn hidden_final\", hidden.shape)\n",
    "#             print(hidden.shape)\n",
    "#         last_layer = output[:,-1,:self.hidden_size]\n",
    "#         first_layer = output[:,0,self.hidden_size:]\n",
    "#         hidden = first_layer + last_layer\n",
    "        return output, hidden, c\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        if self.rnn_type == 'gru' :\n",
    "            return torch.zeros(self.n_layers*2, bs, self.hidden_size).to(device)\n",
    "        elif self.rnn_type == 'lstm':\n",
    "            return torch.zeros(self.n_layers*2,bs,self.hidden_size).to(device),torch.zeros(self.n_layers*2,bs,self.hidden_size).to(device)\n",
    "\n",
    "class Attention_Module(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super(Attention_Module, self).__init__()\n",
    "        self.l1 = Linear(hidden_dim, output_dim, bias = False)\n",
    "        self.l2 = Linear(hidden_dim+output_dim, output_dim, bias =  False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outs, src_lens):\n",
    "        ''' hiddden: bsz x hidden_dim\n",
    "        encoder_outs: bsz x sq_len x encoder dim (output_dim)\n",
    "        src_lens: bsz\n",
    "        \n",
    "        x: bsz x output_dim\n",
    "        attn_score: bsz x sq_len'''\n",
    "        x = self.l1(hidden)\n",
    "        att_score = (encoder_outs.transpose(0,1) * x.unsqueeze(0)).sum(dim = 2)\n",
    "        seq_mask = sequence_mask(src_lens, max_len = max(src_lens).item()).transpose(0,1)\n",
    "        masked_att = seq_mask*att_score\n",
    "        masked_att[masked_att==0] = -1e10\n",
    "        attn_scores = F.softmax(masked_att, dim=0)\n",
    "        x = (attn_scores.unsqueeze(2) * encoder_outs.transpose(0,1)).sum(dim=0)\n",
    "        x = torch.tanh(self.l2(torch.cat((x, hidden), dim=1)))\n",
    "        return x, attn_scores\n",
    "        \n",
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, embed_dim, hidden_size, n_layers = 1, attention = False):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        encoder_output_size = hidden_size\n",
    "        self.embedding = Embedding(output_size, embed_dim, PAD_IDX)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.n_layers = n_layers\n",
    "        self.att_layer = Attention_Module(self.hidden_size, encoder_output_size) if attention else None\n",
    "        self.layers = nn.ModuleList([\n",
    "            LSTMCell(\n",
    "                input_size=self.hidden_size + embed_dim if layer == 0 else hidden_size,\n",
    "                hidden_size=hidden_size,\n",
    "            )\n",
    "            for layer in range(self.n_layers)\n",
    "        ])\n",
    "#         if self.rnn_type == 'gru':\n",
    "#             self.rnn = nn.GRU(self.hidden_size + embed_dim, hidden_size,batch_first=True, num_layers = self.n_layers, )\n",
    "#         elif self.rnn_type == 'lstm':\n",
    "#             self.rnn = nn.LSTM(self.hidden_size + embed_dim, hidden_size,batch_first=True, num_layers = self.n_layers)\n",
    "        self.fc_out = nn.Linear(self.hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, input,context_vector, prev_hiddens,prev_cs,encoder_outputs,src_len):\n",
    "        bsz = input.size(0)\n",
    "        output = self.embedding(input)\n",
    "        output = self.dropout(output)\n",
    "#         print(\"decoder Input embedded\", output.shape)\n",
    "        cated_input = torch.cat([output.squeeze(1),context_vector], dim = 1)\n",
    "#         print(\"cated_input\",cated_input.shape)\n",
    "        new_hiddens = []\n",
    "        new_cs = []\n",
    "        for i, rnn in enumerate(self.layers):\n",
    "            hidden, c = rnn(cated_input, (prev_hiddens[i], prev_cs[i]))\n",
    "            cated_input = self.dropout(hidden)\n",
    "            new_hiddens.append(hidden.unsqueeze(0))\n",
    "            new_cs.append(c.unsqueeze(0))\n",
    "        new_hiddens = torch.cat(new_hiddens, dim = 0)\n",
    "        new_cs = torch.cat(new_cs, dim = 0)\n",
    "\n",
    "        # apply attention using the last layer's hidden state\n",
    "        if self.att_layer is not None:\n",
    "            out, attn_score = self.att_layer(hidden, encoder_outputs, src_len)\n",
    "        else:\n",
    "            out = hidden\n",
    "            attn_score = None\n",
    "        out = self.dropout(out)\n",
    "        out_vocab = self.softmax(self.fc_out(out))\n",
    "\n",
    "        return out_vocab, out, new_hiddens, new_cs, attn_score\n",
    "    \n",
    "#     def initHidden(self,bs):\n",
    "#         if self.rnn_type == 'gru' :\n",
    "#             return None\n",
    "#         elif self.rnn_type == 'lstm':\n",
    "#             return torch.zeros(self.n_layers,bs,self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embedding(num_embeddings, embedding_dim, padding_idx):\n",
    "    m = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n",
    "    nn.init.uniform_(m.weight, -0.1, 0.1)\n",
    "    nn.init.constant_(m.weight[padding_idx], 0)\n",
    "    return m\n",
    "\n",
    "\n",
    "def LSTM(input_size, hidden_size, **kwargs):\n",
    "    m = nn.LSTM(input_size, hidden_size,**kwargs)\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "    return m\n",
    "\n",
    "\n",
    "def LSTMCell(input_size, hidden_size, **kwargs):\n",
    "    m = nn.LSTMCell(input_size, hidden_size,**kwargs)\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "    return m\n",
    "\n",
    "\n",
    "def Linear(in_features, out_features, bias=True, dropout=0):\n",
    "    \"\"\"Linear layer (input: N x T x C)\"\"\"\n",
    "    m = nn.Linear(in_features, out_features, bias=bias)\n",
    "    m.weight.data.uniform_(-0.1, 0.1)\n",
    "    if bias:\n",
    "        m.bias.data.uniform_(-0.1, 0.1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.max().item()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.arange(0, max_len).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).repeat([batch_size,1])\n",
    "    seq_range_expand = seq_range_expand.to(device)\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return (seq_range_expand < seq_length_expand).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_decode(encoder,decoder,data_en,data_de,src_len,tar_len,m_type,rand_num = 0.5):\n",
    "#     use_teacher_forcing = True if random.random() < rand_num else False\n",
    "# #     print(\"tar_len\",tar_len)\n",
    "#     bss = data_en.size(0)\n",
    "#     en_hid = encoder.initHidden(bss)\n",
    "#     en_out,en_hid = encoder(data_en, en_hid)\n",
    "#     max_tar_len_batch = max(tar_len).item()\n",
    "#     decoder_hidden = en_hid\n",
    "#     decoder_input = torch.tensor([[SOS_token]]*bss).to(device)\n",
    "# #     c = decoder.initHidden(bss)\n",
    "# #     print(\"max_tar_len_batch\",max_tar_len_batch)\n",
    "#     if use_teacher_forcing:\n",
    "#         d_out = []\n",
    "#         for i in range(max_tar_len_batch):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out)   \n",
    "#             else:\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             d_out.append(decoder_output.unsqueeze(-1))\n",
    "#             decoder_input = data_de[:,i].view(-1,1)\n",
    "#         d_hid = decoder_hidden\n",
    "#         d_out = torch.cat(d_out,dim=-1)\n",
    "#     else:\n",
    "#         d_out = []\n",
    "#         for i in range(max_tar_len_batch):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out)\n",
    "#             else:\n",
    "#                 decoder_output, decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             d_out.append(decoder_output.unsqueeze(-1))\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "# #             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             decoder_input = topi.squeeze().view(-1,1)\n",
    "#         d_hid = decoder_hidden\n",
    "#         d_out = torch.cat(d_out,dim=-1)\n",
    "#     return d_out, d_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_decode(encoder,decoder,data_en,data_de,src_len,tar_len,m_type,rand_num = 0.5):\n",
    "#     use_teacher_forcing = True if random.random() < rand_num else False\n",
    "# #     print(\"tar_len\",tar_len)\n",
    "#     bss = data_en.size(0)\n",
    "#     en_out,en_hid,c = encoder(data_en, src_len)\n",
    "#     max_tar_len_batch = max(tar_len).item()\n",
    "#     decoder_hidden = en_hid\n",
    "#     decoder_input = torch.tensor([[SOS_token]]*bss).to(device)\n",
    "# #     print(\"max_tar_len_batch\",max_tar_len_batch)\n",
    "#     if use_teacher_forcing:\n",
    "#         d_out = []\n",
    "#         for i in range(max_tar_len_batch):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden, c = decoder(decoder_input,decoder_hidden,en_out,src_len,c)   \n",
    "#             else:\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             d_out.append(decoder_output.unsqueeze(-1))\n",
    "#             decoder_input = data_de[:,i].view(-1,1)\n",
    "#         d_hid = decoder_hidden\n",
    "#         d_out = torch.cat(d_out,dim=-1)\n",
    "# #         print(\"softmax mat\", d_out.shape)\n",
    "#     else:\n",
    "#         d_out = []\n",
    "#         for i in range(max_tar_len_batch):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out,src_len,c)\n",
    "#             else:\n",
    "#                 decoder_output, decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             d_out.append(decoder_output.unsqueeze(-1))\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "# #             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             decoder_input = topi.squeeze().view(-1,1)\n",
    "#         d_hid = decoder_hidden\n",
    "#         d_out = torch.cat(d_out,dim=-1)\n",
    "#     return d_out, d_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_decode(encoder,decoder,data_en,data_de,src_len,tar_len,rand_num = 0.95, val = False):\n",
    "    if not val:\n",
    "        use_teacher_forcing = True if random.random() < rand_num else False\n",
    "    #     print(\"tar_len\",tar_len)\n",
    "        bss = data_en.size(0)\n",
    "        en_out,en_hid,en_c = encoder(data_en, src_len)\n",
    "        max_src_len_batch = max(src_len).item()\n",
    "        max_tar_len_batch = max(tar_len).item()\n",
    "        prev_hiddens = en_hid\n",
    "        prev_cs = en_c\n",
    "        decoder_input = torch.tensor([[SOS_token]]*bss).to(device)\n",
    "        prev_output = torch.zeros((bss, en_out.size(-1))).to(device)\n",
    "        if use_teacher_forcing:\n",
    "            d_out = []\n",
    "            for i in range(max_tar_len_batch):\n",
    "                out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                        prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                        src_len)\n",
    "                d_out.append(out_vocab.unsqueeze(-1))\n",
    "                decoder_input = data_de[:,i].view(-1,1)\n",
    "            d_out = torch.cat(d_out,dim=-1)\n",
    "    #         print(\"softmax mat\", d_out.shape)\n",
    "        else:\n",
    "            d_out = []\n",
    "            for i in range(max_tar_len_batch):\n",
    "                out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                        prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                        src_len)\n",
    "                d_out.append(out_vocab.unsqueeze(-1))\n",
    "                topv, topi = out_vocab.topk(1)\n",
    "                decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "    #             decoder_input = topi.squeeze().view(-1,1)\n",
    "            d_out = torch.cat(d_out,dim=-1)\n",
    "        return d_out\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        bss = data_en.size(0)\n",
    "        en_out,en_hid,en_c = encoder(data_en, src_len)\n",
    "        max_src_len_batch = max(src_len).item()\n",
    "        max_tar_len_batch = max(tar_len).item()\n",
    "        prev_hiddens = en_hid\n",
    "        prev_cs = en_c\n",
    "        decoder_input = torch.tensor([[SOS_token]]*bss).to(device)\n",
    "        prev_output = torch.zeros((bss, en_out.size(-1))).to(device)\n",
    "        d_out = []\n",
    "        for i in range(max_tar_len_batch):\n",
    "            out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                    prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                    src_len)\n",
    "            d_out.append(out_vocab.unsqueeze(-1))\n",
    "            topv, topi = out_vocab.topk(1)\n",
    "            decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             decoder_input = topi.squeeze().view(-1,1)\n",
    "        d_out = torch.cat(d_out,dim=-1)\n",
    "        return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_cel_loss(input,target,nll):\n",
    "    input = input.transpose(1,2)\n",
    "    bs, sl = input.size()[:2]\n",
    "    return nll(input.contiguous().view(bs*sl,-1),target.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(encoder_optimizer,decoder_optimizer, encoder, decoder, loss_fun,m_type, dataloader, en_lang,\\\n",
    "                num_epochs=60, val_every = 1, train_bleu_every = 10,clip = 0.1, rm = 0.8, enc_scheduler = None,\\\n",
    "               dec_scheduler = None):\n",
    "    best_score = 0\n",
    "    best_bleu = 0\n",
    "    loss_hist = {'train': [], 'val_train': []}\n",
    "    bleu_hist = {'train': [], 'validate': []}\n",
    "    best_encoder_wts = None\n",
    "    best_decoder_wts = None\n",
    "#     train_sorted = train.sort_values('en_len', ascending = False)\n",
    "    phases = ['train','val_train']\n",
    "#     phases = ['train']\n",
    "    for epoch in range(num_epochs):\n",
    "        bs_dict = {'train':128,'validate':1, 'train_val':1,'val_train':128}\n",
    "#         train_used = shuffle_sorted_batches(train_sorted, bs_dict['train'])\n",
    "#         train_used = train.iloc[:50]\n",
    "        train_used = train\n",
    "        collate_fn_dict = {'train':vocab_collate_func, 'validate':vocab_collate_func_val,\\\n",
    "                           'train_val':vocab_collate_func_val,'val_train':vocab_collate_func}\n",
    "        transformed_dataset = {'train': Vietnamese(train_used),\n",
    "                               'validate': Vietnamese(val, val = True),\n",
    "                               'train_val':Vietnamese(train.iloc[:50], val = True),\n",
    "                               'val_train':Vietnamese(val)\n",
    "                                                       }\n",
    "\n",
    "        dataloader = {x: DataLoader(transformed_dataset[x], batch_size=bs_dict[x], collate_fn=collate_fn_dict[x],\n",
    "                            shuffle=True, num_workers=0) for x in ['train', 'validate', 'train_val','val_train']}\n",
    "        for ex, phase in enumerate(phases):\n",
    "            start = time.time()\n",
    "            total = 0\n",
    "            top1_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if phase == 'train':\n",
    "                encoder.train()\n",
    "                decoder.train()\n",
    "            else:\n",
    "                encoder.eval()\n",
    "                decoder.eval()\n",
    "            for data in dataloader[phase]:\n",
    "                encoder_optimizer.zero_grad()\n",
    "                decoder_optimizer.zero_grad()\n",
    "\n",
    "                encoder_i = data[0].to(device)\n",
    "                decoder_i = data[1].to(device)\n",
    "                src_len = data[2].to(device)\n",
    "                tar_len = data[3].to(device)\n",
    "#                 print(encoder_i.shape)\n",
    "                if phase == 'val_train':                \n",
    "                    out = encode_decode(encoder,decoder,encoder_i,decoder_i,src_len,tar_len,rand_num=rm,val = True )\n",
    "                else:\n",
    "                    out = encode_decode(encoder,decoder,encoder_i,decoder_i,src_len,tar_len,rand_num=rm,val = False )\n",
    "                N = decoder_i.size(0)\n",
    "#                 out = out.view(-1,en_lang.n_words)\n",
    "#                 decoder_i = decoder_i.view(-1)\n",
    "#                 if loss_fun == 'masked_cel':\n",
    "#                     loss = masked_cross_entropy(out.float(), decoder_i.long(), tar_len)\n",
    "#                 else:\n",
    "#                     loss = flatten_cel_loss(out.float(), decoder_i.long(),loss_fun)\n",
    "                loss = loss_fun(out.float(), decoder_i.long())\n",
    "                running_loss += loss.item() * N\n",
    "                \n",
    "                total += N\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "                    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "                    encoder_optimizer.step()\n",
    "                    decoder_optimizer.step()\n",
    "                    \n",
    "            epoch_loss = running_loss / total \n",
    "            loss_hist[phase].append(epoch_loss)\n",
    "            print(\"epoch {} {} loss = {}, time = {}\".format(epoch, phase, epoch_loss,\n",
    "                                                                           time.time() - start))\n",
    "#             if epoch%train_bleu_every ==0:\n",
    "#                 train_loss, train_bleu_score = validation(encoder,decoder, dataloader['train'],loss_fun, en_lang,max_len,m_type)\n",
    "#                 bleu_hist['train'].append(train_bleu_score)\n",
    "#                 print(\"Train BLEU = \", train_bleu_score)\n",
    "        if (enc_scheduler is not None) and (dec_scheduler is not None):\n",
    "            enc_scheduler.step(epoch_loss)\n",
    "            dec_scheduler.step(epoch_loss)\n",
    "        if epoch%val_every == 0:\n",
    "            val_bleu_score = validation_new(encoder,decoder, dataloader['validate'], en_lang, m_type)\n",
    "            bleu_hist['validate'].append(val_bleu_score)\n",
    "            print(\"validation BLEU = \", val_bleu_score)\n",
    "            if val_bleu_score > best_bleu:\n",
    "                best_bleu = val_bleu_score\n",
    "                best_encoder_wts = encoder.state_dict()\n",
    "                best_decoder_wts = decoder.state_dict()\n",
    "        print('='*50)\n",
    "    encoder.load_state_dict(best_encoder_wts)\n",
    "    decoder.load_state_dict(best_decoder_wts)\n",
    "    print(\"Training completed. Best BLEU is {}\".format(best_bleu))\n",
    "    return encoder,decoder,loss_hist,bleu_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validation_new(encoder, decoder, val_dataloader, lang_en,m_type):\n",
    "#     encoder.train(False)\n",
    "#     decoder.train(False)\n",
    "#     pred_corpus = []\n",
    "#     true_corpus = []\n",
    "#     running_loss = 0\n",
    "#     running_total = 0\n",
    "#     bl = BLEU_SCORE()\n",
    "#     for data in val_dataloader:\n",
    "#         encoder_i = data[0].to(device)\n",
    "#         src_len = data[2].to(device)\n",
    "#         bs,sl = encoder_i.size()[:2]\n",
    "#         en_hid = encoder.initHidden(bs)\n",
    "#         en_out,en_hid = encoder(encoder_i, en_hid)\n",
    "#         decoder_hidden = en_hid\n",
    "#         decoder_input = torch.tensor([[SOS_token]]*bs).to(device)\n",
    "# #         c = decoder.initHidden(bs)\n",
    "#         d_out = []\n",
    "#         for i in range(sl+20):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out)\n",
    "#             else:\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             d_out.append(topi.item())\n",
    "#             if topi.item() == EOS_token:\n",
    "#                 break\n",
    "#         d_hid = decoder_hidden\n",
    "        \n",
    "#         true_corpus.append(data[-1])\n",
    "#         pred_sent = convert_id_list_2_sent(d_out,lang_en)\n",
    "#         pred_corpus.append(pred_sent)\n",
    "# #         print(\"True Sentence:\",data[-1])\n",
    "# #         print(\"Pred Sentence:\", pred_sent)\n",
    "# #         print('-*'*50)\n",
    "#     score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validation_new(encoder, decoder, val_dataloader, lang_en,m_type):\n",
    "#     encoder.train(False)\n",
    "#     decoder.train(False)\n",
    "#     pred_corpus = []\n",
    "#     true_corpus = []\n",
    "#     running_loss = 0\n",
    "#     running_total = 0\n",
    "#     bl = BLEU_SCORE()\n",
    "#     for data in val_dataloader:\n",
    "#         encoder_i = data[0].to(device)\n",
    "#         src_len = data[2].to(device)\n",
    "#         bs,sl = encoder_i.size()[:2]\n",
    "#         en_out,en_hid = encoder(encoder_i,src_len)\n",
    "#         decoder_hidden = en_hid\n",
    "#         decoder_input = torch.tensor([[SOS_token]]*bs).to(device)\n",
    "#         c = decoder.initHidden(bs)\n",
    "#         d_out = []\n",
    "#         for i in range(sl+20):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out,src_len,c)\n",
    "#             else:\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             d_out.append(topi.item())\n",
    "#             if topi.item() == EOS_token:\n",
    "#                 break\n",
    "#         d_hid = decoder_hidden\n",
    "        \n",
    "#         true_corpus.append(data[-1])\n",
    "#         pred_sent = convert_id_list_2_sent(d_out,lang_en)\n",
    "#         pred_corpus.append(pred_sent)\n",
    "# #         print(\"True Sentence:\",data[-1])\n",
    "# #         print(\"Pred Sentence:\", pred_sent)\n",
    "# #         print('-*'*50)\n",
    "#     score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_new(encoder, decoder, val_dataloader, lang_en,m_type, verbose = False):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    pred_corpus = []\n",
    "    true_corpus = []\n",
    "    running_loss = 0\n",
    "    running_total = 0\n",
    "    bl = BLEU_SCORE()\n",
    "    for data in val_dataloader:\n",
    "        encoder_i = data[0].to(device)\n",
    "        src_len = data[2].to(device)\n",
    "        bs,sl = encoder_i.size()[:2]\n",
    "        en_out,en_hid,en_c = encoder(encoder_i,src_len)\n",
    "        max_src_len_batch = max(src_len).item()\n",
    "        prev_hiddens = en_hid\n",
    "        prev_cs = en_c\n",
    "        decoder_input = torch.tensor([[SOS_token]]*bs).to(device)\n",
    "        prev_output = torch.zeros((bs, en_out.size(-1))).to(device)\n",
    "        d_out = []\n",
    "        for i in range(sl*2):\n",
    "            out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                    prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                    src_len)\n",
    "            topv, topi = out_vocab.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "            d_out.append(topi.item())\n",
    "            decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "        \n",
    "        true_corpus.append(data[-1])\n",
    "        pred_sent = convert_id_list_2_sent(d_out,lang_en)\n",
    "        pred_corpus.append(pred_sent)\n",
    "        if verbose:\n",
    "            print(\"True Sentence:\",data[-1])\n",
    "            print(\"Pred Sentence:\", pred_sent)\n",
    "            print('-*'*50)\n",
    "    score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_cross_entropy(logits, target, length):\n",
    "    logits = logits.transpose(1,2)\n",
    "#     print(\"logits\",logits.shape)\n",
    "#     print(\"target\",target.shape)\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.contiguous().view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "#     log_probs_flat = F.log_softmax(logits_flat, dim = 1)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "#     print(\"tar_flat\", target_flat.shape)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(logits_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask\n",
    "    loss = losses.sum() / length.float().sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'masked_cel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Old Interesting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(vi_lang.n_words,512,512, 2).to(device)\n",
    "decoder = AttentionDecoderRNN(en_lang.n_words,512,1024,n_layers=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# encoder = OldEncoderRNN(vi_lang.n_words,512,bi = True).to(device)\n",
    "# decoder = OldAttentionDecoderRNN(512,en_lang.n_words, True, MAX_LEN, attention_type='t2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss = 5.654132865225413, time = 341.1948525905609\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 1 train loss = 5.45065745284289, time = 341.9193711280823\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 2 train loss = 5.210996340336155, time = 342.40592312812805\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 4 train loss = 4.809566239472573, time = 341.6780881881714\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 5 train loss = 4.63142532622266, time = 341.56193590164185\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 6 train loss = 4.520703522670287, time = 341.8052592277527\n",
      "validation BLEU =  0.007257456178771249\n",
      "==================================================\n",
      "epoch 7 train loss = 4.4197971115632395, time = 341.1301064491272\n",
      "validation BLEU =  0.00778988176186667\n",
      "==================================================\n",
      "epoch 8 train loss = 4.318348191080374, time = 341.3023076057434\n",
      "validation BLEU =  0.00873574484162468\n",
      "==================================================\n",
      "epoch 9 train loss = 4.237790871660339, time = 341.7362952232361\n",
      "validation BLEU =  0.01489571311812371\n",
      "==================================================\n",
      "epoch 10 train loss = 4.151050939980724, time = 341.4068603515625\n",
      "validation BLEU =  0.019931957373692067\n",
      "==================================================\n",
      "epoch 11 train loss = 4.091922725855361, time = 341.15118384361267\n",
      "validation BLEU =  0.029661319317699324\n",
      "==================================================\n",
      "epoch 12 train loss = 3.9871769643770034, time = 341.45858216285706\n",
      "validation BLEU =  0.026448033178258345\n",
      "==================================================\n",
      "epoch 13 train loss = 3.913650239591969, time = 341.27526092529297\n",
      "validation BLEU =  0.03262531539161065\n",
      "==================================================\n",
      "epoch 14 train loss = 3.8498835832313856, time = 340.95101499557495\n",
      "validation BLEU =  0.044428241859491846\n",
      "==================================================\n",
      "epoch 15 train loss = 3.7791828754784245, time = 340.5919189453125\n",
      "validation BLEU =  0.03321728976507814\n",
      "==================================================\n",
      "epoch 16 train loss = 3.73131796845992, time = 341.2179868221283\n",
      "validation BLEU =  0.038820169262083856\n",
      "==================================================\n",
      "epoch 17 train loss = 3.690869427688029, time = 340.93681621551514\n",
      "validation BLEU =  0.05502212762362031\n",
      "==================================================\n",
      "epoch 18 train loss = 3.6422906667641395, time = 341.4393320083618\n",
      "validation BLEU =  0.058218193395599985\n",
      "==================================================\n",
      "epoch 19 train loss = 3.6025976965133, time = 342.0387489795685\n",
      "validation BLEU =  0.06265281052708205\n",
      "==================================================\n",
      "epoch 20 train loss = 3.568165948672502, time = 341.7699897289276\n",
      "validation BLEU =  0.06432711461627151\n",
      "==================================================\n",
      "epoch 21 train loss = 3.467597369658819, time = 341.9801962375641\n",
      "validation BLEU =  0.07283668274696219\n",
      "==================================================\n",
      "epoch 22 train loss = 3.4127586705564568, time = 341.50896525382996\n",
      "validation BLEU =  0.09124435261111917\n",
      "==================================================\n",
      "epoch 23 train loss = 4.11731507090061, time = 662.7810173034668\n",
      "validation BLEU =  3.7549343800802806\n",
      "==================================================\n",
      "epoch 24 train loss = 3.281447067662696, time = 341.5275800228119\n",
      "validation BLEU =  0.08469296828050618\n",
      "==================================================\n",
      "epoch 25 train loss = 3.271404259174648, time = 341.82329988479614\n",
      "validation BLEU =  0.15599388189696986\n",
      "==================================================\n",
      "epoch 26 train loss = 3.2869543531108163, time = 341.4335904121399\n",
      "validation BLEU =  0.1577493999531032\n",
      "==================================================\n",
      "epoch 27 train loss = 3.230972457758133, time = 341.5713469982147\n",
      "validation BLEU =  0.19278032635104744\n",
      "==================================================\n",
      "epoch 28 train loss = 3.19142589813571, time = 341.66050362586975\n",
      "validation BLEU =  0.1841768342892874\n",
      "==================================================\n",
      "epoch 29 train loss = 3.14125059641754, time = 341.6516077518463\n",
      "validation BLEU =  0.3033989533197111\n",
      "==================================================\n",
      "epoch 30 train loss = 3.115007367013696, time = 341.53219294548035\n",
      "validation BLEU =  0.3382457234701169\n",
      "==================================================\n",
      "epoch 31 train loss = 3.0665265867784455, time = 341.37299036979675\n",
      "validation BLEU =  0.5253105968823382\n",
      "==================================================\n",
      "epoch 32 train loss = 3.024415717351258, time = 342.05147337913513\n",
      "validation BLEU =  0.62985109085486\n",
      "==================================================\n",
      "epoch 33 train loss = 2.9992271762819116, time = 341.3521366119385\n",
      "validation BLEU =  0.7111174465433215\n",
      "==================================================\n",
      "epoch 34 train loss = 2.973018437561273, time = 341.3219199180603\n",
      "validation BLEU =  0.7373088348879125\n",
      "==================================================\n",
      "epoch 35 train loss = 2.9244212736258652, time = 341.13356590270996\n",
      "validation BLEU =  0.6783435354723314\n",
      "==================================================\n",
      "epoch 36 train loss = 2.887372524305964, time = 341.86699175834656\n",
      "validation BLEU =  0.7934873634499011\n",
      "==================================================\n",
      "epoch 37 train loss = 3.7282196400737244, time = 663.0309255123138\n",
      "validation BLEU =  5.422935553126234\n",
      "==================================================\n",
      "epoch 38 train loss = 2.7775619442239425, time = 341.5769703388214\n",
      "validation BLEU =  0.7515482635411938\n",
      "==================================================\n",
      "epoch 39 train loss = 2.822405433327482, time = 341.5337553024292\n",
      "validation BLEU =  0.8095145218786286\n",
      "==================================================\n",
      "epoch 40 train loss = 2.756222195607683, time = 341.53091645240784\n",
      "validation BLEU =  0.9110316293259347\n",
      "==================================================\n",
      "epoch 41 train loss = 2.721858608548948, time = 340.9498107433319\n",
      "validation BLEU =  0.918893890140245\n",
      "==================================================\n",
      "epoch 42 train loss = 2.7066624271356634, time = 341.8966417312622\n",
      "validation BLEU =  1.033976401522409\n",
      "==================================================\n",
      "epoch 43 train loss = 2.68261871081093, time = 341.18897104263306\n",
      "validation BLEU =  1.0486068458813393\n",
      "==================================================\n",
      "epoch 44 train loss = 3.5252452283543056, time = 662.3115556240082\n",
      "validation BLEU =  5.361300296846215\n",
      "==================================================\n",
      "epoch 45 train loss = 2.6183942231628192, time = 341.8273367881775\n",
      "validation BLEU =  1.0240641803494395\n",
      "==================================================\n",
      "epoch 46 train loss = 2.5875116109712106, time = 341.2915151119232\n",
      "validation BLEU =  1.3144701708752409\n",
      "==================================================\n",
      "epoch 47 train loss = 2.5632219784778774, time = 341.41440892219543\n",
      "validation BLEU =  1.3706422127766096\n",
      "==================================================\n",
      "epoch 48 train loss = 2.550861967960378, time = 341.4405016899109\n",
      "validation BLEU =  1.3821948611330461\n",
      "==================================================\n",
      "epoch 49 train loss = 3.414882306602232, time = 662.9478738307953\n",
      "validation BLEU =  5.737080525314268\n",
      "==================================================\n",
      "Training completed. Best BLEU is 5.737080525314268\n"
     ]
    }
   ],
   "source": [
    "enc, dec, loss_hist, acc_hist = train_model(encoder_optimizer, decoder_optimizer, encoder, decoder, criterion,\\\n",
    "                                            \"attention\", dataloader,en_lang, num_epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Sentence: Rachel Pike : The science behind a climate headline\n",
      "Pred Sentence: UKN UKN revolution .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .\n",
      "Pred Sentence: In four minutes , the UKN UKN UKN UKN UKN of of of the the the the the the the , , , , the the the , , , , , , , , , , the the the the the the the the the the the\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
      "Pred Sentence: I want you to know about the great challenges of the challenges that you &apos;ve been to to .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .\n",
      "Pred Sentence: These are things like like like to look to the , , , , , , , , , UKN UKN UKN\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: They are both two branches of the same field of atmospheric science .\n",
      "Pred Sentence: Both are both UKN of a of a of . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .\n",
      "Pred Sentence: The recent headlines like this as the UKN UKN UKN , which if they UKN the UKN to the the the the\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: That report was written by 620 scientists from 40 countries .\n",
      "Pred Sentence: UKN was written by the UKN UKN UKN UKN .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: They wrote almost a thousand pages on the topic .\n",
      "Pred Sentence: They wrote a thousand pages on this video .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .\n",
      "Pred Sentence: And all all of are by by by by UKN of of UKN UKN and .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: It &apos;s a big community . It &apos;s such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .\n",
      "Pred Sentence: It &apos;s a huge community , and , , , , the the the the the the the the the the the the the the the . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Over 15,000 scientists go to San Francisco every year for that .\n",
      "Pred Sentence: More , we invited to San Francisco at San Francisco .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And every one of those scientists is in a research group , and every research group studies a wide variety of topics .\n",
      "Pred Sentence: Every human group is a group group , a group of students , and each of them .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: For us at Cambridge , it &apos;s as varied as the El Niño oscillation , which affects weather and climate , to the assimilation of satellite data , to emissions from crops that produce biofuels , which is what I happen to study .\n",
      "Pred Sentence: For us , , , , the the the the of of of of , , , , , , , , , , , , , , , , , , , , , , , , the the the the the the . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And in each one of these research areas , of which there are even more , there are PhD students , like me , and we study incredibly narrow topics , things as narrow as a few processes or a few molecules .\n",
      "Pred Sentence: Each of these projects projects more , , , , , , , , , , , I , , , , , , , , , , , , some some . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And one of the molecules I study is called isoprene , which is here . It &apos;s a small organic molecule . You &apos;ve probably never heard of it .\n",
      "Pred Sentence: One of the UKN of this is called called UKN . UKN . It &apos;s a . a . a , , , , you . . . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: The weight of a paper clip is approximately equal to 900 zeta-illion -- 10 to the 21st -- molecules of isoprene .\n",
      "Pred Sentence: A little of UKN UKN UKN UKN UKN UKN UKN -- -- -- -- -- -- -- -- .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: But despite its very small weight , enough of it is emitted into the atmosphere every year to equal the weight of all the people on the planet .\n",
      "Pred Sentence: UKN small , very small , but the amount of energy is actually in the atmosphere of the the of .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: It &apos;s a huge amount of stuff . It &apos;s equal to the weight of methane .\n",
      "Pred Sentence: It &apos;s a huge amount of carbon emissions .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And because it &apos;s so much stuff , it &apos;s really important for the atmospheric system .\n",
      "Pred Sentence: It &apos;s because huge huge huge amount of water , it &apos;s important .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Because it &apos;s important to the atmospheric system , we go to all lengths to study this thing .\n",
      "Pred Sentence: It &apos;s because it &apos;s because the environment , the system that we &apos;re going to to the we the the .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We blow it up and look at the pieces .\n",
      "Pred Sentence: We made it and and and we a little . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: This is the EUPHORE Smog Chamber in Spain .\n",
      "Pred Sentence: This is UKN UKN UKN in Spain .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Atmospheric explosions , or full combustion , takes about 15,000 times longer than what happens in your car .\n",
      "Pred Sentence: UKN explosions , UKN UKN UKN , UKN times times times the of of\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: But still , we look at the pieces .\n",
      "Pred Sentence: And sometimes we &apos;re still small .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We run enormous models on supercomputers ; this is what I happen to do .\n",
      "Pred Sentence: We created the models model on computers .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Our models have hundreds of thousands of grid boxes calculating hundreds of variables each , on minute timescales .\n",
      "Pred Sentence: Our data has thousands of thousands of UKN UKN UKN hundreds of hundreds of .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Sentence: And it takes weeks to perform our integrations .\n",
      "Pred Sentence: It &apos;s takes a week of weeks .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And we perform dozens of integrations in order to understand what &apos;s happening .\n",
      "Pred Sentence: We need hundreds of these kinds of algorithms to do that .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We also fly all over the world looking for this thing .\n",
      "Pred Sentence: We &apos;re around around the world to to .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: I recently joined a field campaign in Malaysia . There are others .\n",
      "Pred Sentence: I recently joined a UKN in the UKN . . . . . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We found a global atmospheric watchtower there , in the middle of the rainforest , and hung hundreds of thousands of dollars worth of scientific equipment off this tower , to look for isoprene , and of course , other things while we were there .\n",
      "Pred Sentence: We found a global atmospheric global in the , , , and and and and we and to to to thousands thousands thousands of thousands of , , , , , , , , , , and , . . . . . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: This is the tower in the middle of the rainforest , from above .\n",
      "Pred Sentence: This is the UKN UKN in the middle of the the .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And this is the tower from below .\n",
      "Pred Sentence: \n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And on part of that field campaign we even brought an aircraft with us .\n",
      "Pred Sentence: We have we we we .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And this plane , the model , BA146 , which was run by FAAM , normally flies 120 to 130 people .\n",
      "Pred Sentence: This slide , UKN , UKN , which is UKN UKN , UKN UKN .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: So maybe you took a similar aircraft to get here today .\n",
      "Pred Sentence: Very probably you have on a new future .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: But we didn &apos;t just fly it . We were flying at 100 meters above the top of the canopy to measure this molecule -- incredibly dangerous stuff .\n",
      "Pred Sentence: We didn &apos;t fly just how fast it was to fly to the fly to the surface of the surface of the reef , and it &apos;s very pretty cheap .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We have to fly at a special incline in order to make the measurements .\n",
      "Pred Sentence: We have to UKN UKN UKN UKN ,\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We hire military and test pilots to do the maneuvering .\n",
      "Pred Sentence: We hire military and pilots to choose the police .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We have to get special flight clearance .\n",
      "Pred Sentence: UKN to .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And as you come around the banks in these valleys , the forces can get up to two Gs .\n",
      "Pred Sentence: When you go around the the the Valley Valley , the , the , that are .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And the scientists have to be completely harnessed in in order to make measurements while they &apos;re on board .\n",
      "Pred Sentence: UKN have been to to to to to to to to to to .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: So , as you can imagine , the inside of this aircraft doesn &apos;t look like any plane you would take on vacation .\n",
      "Pred Sentence: So you can imagine , in the way , the right thing is not going to be any any any .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: It &apos;s a flying laboratory that we took to make measurements in the region of this molecule .\n",
      "Pred Sentence: It &apos;s a laboratory laboratory that we can try to do .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We do all of this to understand the chemistry of one molecule .\n",
      "Pred Sentence: We do it to to to to the molecular molecular molecule .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And when one student like me has some sort of inclination or understanding about that molecule , they write one scientific paper on the subject .\n",
      "Pred Sentence: When my dad was a a a about or or or , , , , , , , , a a . a . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And out of that field campaign we &apos;ll probably get a few dozen papers on a few dozen processes or molecules .\n",
      "Pred Sentence: And the results of that that we have able to a a a a a a of of\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And as a body of knowledge builds up , it will form one subsection , or one sub-subsection of an assessment like the IPCC , although we have others .\n",
      "Pred Sentence: When a of of of this it it it , , a a , , a a a a or or or , , , , , ,\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And each one of the 11 chapters of the IPCC has six to ten subsections .\n",
      "Pred Sentence: Every single chapter of the UKN of the IPCC has about 10 words .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: So you can imagine the scale of the effort .\n",
      "Pred Sentence: So you can see how this great movement of this work is going to be .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.89490079655882"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_new(enc,dec,dataloader['train_val'],en_lang, 'attention', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second with shuffled batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(vi_lang.n_words,512,512, 2).to(device)\n",
    "decoder = AttentionDecoderRNN(en_lang.n_words,512,1024,n_layers=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = OldEncoderRNN(vi_lang.n_words,512,bi = True).to(device)\n",
    "# decoder = OldAttentionDecoderRNN(512,en_lang.n_words, True, MAX_LEN, attention_type='t2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_optimizer = optim.Adam(encoder.parameters(), lr = 5e-3)\n",
    "# decoder_optimizer = optim.Adam(decoder.parameters(), lr = 5e-3)\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-4,  patience=0)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-4,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss = 5.448357953040741, time = 663.8662695884705\n",
      "epoch 0 val_train loss = 6.205217158380743, time = 3.224254846572876\n",
      "validation BLEU =  1.2640656972990225\n",
      "==================================================\n",
      "epoch 1 train loss = 4.466191016466267, time = 664.2587950229645\n",
      "epoch 1 val_train loss = 6.539027952621412, time = 3.2456345558166504\n",
      "validation BLEU =  3.1767704213891608\n",
      "==================================================\n",
      "epoch 2 train loss = 4.064321100128371, time = 664.3784079551697\n",
      "epoch 2 val_train loss = 5.843420616835826, time = 3.242091417312622\n",
      "validation BLEU =  4.054449644495632\n",
      "==================================================\n",
      "epoch 3 train loss = 3.8865785588489707, time = 664.5217673778534\n",
      "epoch 3 val_train loss = 5.926745017620291, time = 3.223454713821411\n",
      "validation BLEU =  5.074489796898661\n",
      "==================================================\n",
      "epoch 4 train loss = 3.735492187864453, time = 664.6877009868622\n",
      "epoch 4 val_train loss = 5.5243214929141455, time = 3.2586846351623535\n",
      "validation BLEU =  5.5365409862525725\n",
      "==================================================\n",
      "epoch 5 train loss = 3.663915344385771, time = 666.0000283718109\n",
      "epoch 5 val_train loss = 5.482947348044122, time = 3.227259397506714\n",
      "validation BLEU =  5.593861638685833\n",
      "==================================================\n",
      "epoch 6 train loss = 3.5708651286856785, time = 665.2207663059235\n",
      "epoch 6 val_train loss = 5.5066977464814295, time = 3.247077703475952\n",
      "validation BLEU =  6.195420254934961\n",
      "==================================================\n",
      "epoch 7 train loss = 3.4690932168812996, time = 664.8256514072418\n",
      "epoch 7 val_train loss = 5.373988258349782, time = 3.2429251670837402\n",
      "validation BLEU =  6.156291188566895\n",
      "==================================================\n",
      "epoch 8 train loss = 3.44974876060501, time = 664.9057550430298\n",
      "epoch 8 val_train loss = 5.380049382098465, time = 3.2341232299804688\n",
      "validation BLEU =  6.352290312467939\n",
      "==================================================\n",
      "epoch 9 train loss = 3.3946704741856335, time = 664.8986382484436\n",
      "epoch 9 val_train loss = 5.456845922801021, time = 3.224208354949951\n",
      "validation BLEU =  6.631802710457964\n",
      "==================================================\n",
      "epoch 10 train loss = 3.3399349680609807, time = 665.6172626018524\n",
      "epoch 10 val_train loss = 5.5342193597498754, time = 3.2329022884368896\n",
      "validation BLEU =  6.773120766583466\n",
      "==================================================\n",
      "epoch 11 train loss = 3.345533648719837, time = 665.532746553421\n",
      "epoch 11 val_train loss = 5.536223673294019, time = 3.253523349761963\n",
      "validation BLEU =  6.844707597387208\n",
      "==================================================\n",
      "epoch 12 train loss = 3.33427920146346, time = 664.8599767684937\n",
      "epoch 12 val_train loss = 5.505463577595419, time = 3.2258145809173584\n",
      "validation BLEU =  6.771193642122732\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "enc, dec, loss_hist, acc_hist = train_model(encoder_optimizer, decoder_optimizer, encoder, decoder, criterion,\\\n",
    "                                            \"attention\", dataloader,en_lang, num_epochs = 15, rm = 0.95,\\\n",
    "                                           enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_new(enc,dec,dataloader['train_val'],en_lang, 'attention', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
