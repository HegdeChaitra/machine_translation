{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import pdb\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import itertools\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import argparse\n",
    "from torch import optim\n",
    "import time\n",
    "import os\n",
    "from bleu_score import BLEU_SCORE\n",
    "from models_viet import EncoderRNN, AttentionDecoderRNN, DecoderRNN\n",
    "from load_dataset_viet import *\n",
    "from define_training_viet import *\n",
    "import torchtext\n",
    "from torch.utils.data import BatchSampler\n",
    "from torch.utils.data import SequentialSampler\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vietnamese(Dataset):\n",
    "    def __init__(self, df, val = False):\n",
    "        self.df = df\n",
    "        self.val = val\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        english = self.df.iloc[idx,:]['en_idized']\n",
    "        viet = self.df.iloc[idx,:]['vi_idized']\n",
    "        en_len = self.df.iloc[idx,:]['en_len']\n",
    "        vi_len = self.df.iloc[idx,:]['vi_len']\n",
    "        if self.val:\n",
    "            en_data = self.df.iloc[idx,:]['en_data']\n",
    "            return [viet,english,vi_len,en_len,en_data]\n",
    "        else:\n",
    "            return [viet,english,vi_len,en_len]\n",
    "    \n",
    "    \n",
    "def vocab_collate_func(batch):\n",
    "    MAX_LEN_EN = 48\n",
    "    MAX_LEN_VI = 48\n",
    "    en_data = []\n",
    "    vi_data = []\n",
    "    en_len = []\n",
    "    vi_len = []\n",
    "    for datum in batch:\n",
    "        en_len.append(datum[3])\n",
    "        vi_len.append(datum[2])\n",
    "    max_batch_length_en = max(en_len)\n",
    "    max_batch_length_vi = max(vi_len)\n",
    "    if max_batch_length_en < MAX_LEN_EN:\n",
    "        MAX_LEN_EN = max_batch_length_en\n",
    "    if max_batch_length_vi < MAX_LEN_VI:\n",
    "        MAX_LEN_VI = max_batch_length_vi\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        if datum[2]>MAX_LEN_VI:\n",
    "            padded_vec_s1 = np.array(datum[0])[:MAX_LEN_VI]\n",
    "        else:\n",
    "            padded_vec_s1 = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,MAX_LEN_VI - datum[2])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        if datum[3]>MAX_LEN_EN:\n",
    "            padded_vec_s2 = np.array(datum[1])[:MAX_LEN_EN]\n",
    "        else:\n",
    "            padded_vec_s2 = np.pad(np.array(datum[1]),\n",
    "                                pad_width=((0,MAX_LEN_EN - datum[3])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        en_data.append(padded_vec_s2)\n",
    "        vi_data.append(padded_vec_s1)\n",
    "    vi_data = np.array(vi_data)\n",
    "    en_data = np.array(en_data)\n",
    "    vi_len = np.array(vi_len)\n",
    "    en_len = np.array(en_len)\n",
    "    sorted_vi_len = np.argsort(-vi_len)\n",
    "    vi_data = vi_data[sorted_vi_len]\n",
    "    en_data = en_data[sorted_vi_len]\n",
    "    vi_len = vi_len[sorted_vi_len]\n",
    "    en_len = en_len[sorted_vi_len]\n",
    "#     print(en_len)\n",
    "    vi_len[vi_len>MAX_LEN_VI] = MAX_LEN_VI\n",
    "    en_len[en_len>MAX_LEN_EN] = MAX_LEN_EN\n",
    "        \n",
    "    return [torch.from_numpy(vi_data), torch.from_numpy(en_data),\n",
    "            torch.from_numpy(vi_len), torch.from_numpy(en_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_collate_func_val(batch):\n",
    "    return [torch.from_numpy(np.array(batch[0][0])).unsqueeze(0), torch.from_numpy(np.array(batch[0][1])).unsqueeze(0),\n",
    "            torch.from_numpy(np.array(batch[0][2])).unsqueeze(0), torch.from_numpy(np.array(batch[0][3])).unsqueeze(0),batch[0][4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_LEN = 48\n",
    "train,val,en_lang,vi_lang = train_val_load(48, \"\", '/scratch/ark576/machine_translation_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_sorted_batches(train, bs):\n",
    "    batch_samp_list = list(BatchSampler(SequentialSampler(train), bs, drop_last = False))\n",
    "    np.random.shuffle(batch_samp_list)\n",
    "    batch_samp_list_merged = list(itertools.chain(*batch_samp_list))\n",
    "    return train.iloc[batch_samp_list_merged,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sorted = train.sort_values('en_len', ascending = False)\n",
    "bs_dict = {'train':128,'validate':1, 'train_val':1}\n",
    "# train_used = train_sorted\n",
    "train_used = train.sample(10)\n",
    "train_used = shuffle_sorted_batches(train_sorted,bs_dict)\n",
    "collate_fn_dict = {'train':vocab_collate_func, 'validate':vocab_collate_func_val, 'train_val':vocab_collate_func_val}\n",
    "transformed_dataset = {'train': Vietnamese(train_used),\n",
    "                       'validate': Vietnamese(val, val = True),\n",
    "                       'train_val':Vietnamese(train.iloc[:50], val = True)\n",
    "                                               }\n",
    "\n",
    "dataloader = {x: DataLoader(transformed_dataset[x], batch_size=bs_dict[x], collate_fn=collate_fn_dict[x],\n",
    "                    shuffle=False, num_workers=0) for x in ['train', 'validate', 'train_val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sample = next(iter(dataloader['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 17])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 11])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 17, 16, 16, 16, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14,\n",
       "        13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  7,  7,  7,  7,\n",
       "         6,  5])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: TED follows Nicholas Negroponte to Colombia as he delivers laptops inside territory once controlled by guerrillas . His partner ? Colombia &apos;s Defense Department , who see One Laptop per Child as an investment in the region . EOS\n",
      "Viet: TED theo chân Nicholas UKN đến với Colombia khi mà ông phân_phát laptop trong khu_vực đã từng bị các chiến sỹ du_kích kiểm_soát . UKN của_ông ta ư ? Đó là_là Bộ Quốc_phòng Colombia , cơ_quan này xem chương_trình Một đứa trẻ một laptop là một sự đầu_tư\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I was a UKN living statue called the UKN UKN , and I love telling people l did this for a job , because everybody always wants to know , who are these freaks in real life ? EOS\n",
      "Viet: Tôi tự đóng giả làm một bức tượng sống có tên là 8 - UKN UKN , và tôi thích nói với mọi người rằng tôi làm điều này để kiếm sống , bởi_vì ai cũng luôn_luôn muốn biết , những kẻ gàn_dở này là ai trong cuộc_sống\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: But Murray Gell-Mann yesterday talked about emergent properties ; another name for them could be &quot; architecture &quot; as a metaphor for taking the same old material and thinking about UKN , UKN ways of combining it . EOS\n",
      "Viet: Nhưng Murray Gell - Mann đã bàn về \" các vật ứng_biến \" ngày hôm_qua hay còn có tên_gọi khác là \" kiến_trúc \" như là một phép ẩn_dụ cho việc lấy những vật_liệu bình_thường và nghĩ_ra những cách không hiển_nhiên , không đơn_giản để kết_hợp những vật_liệu\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So , you have a patient with a phantom limb . If the arm has been removed and you have a phantom , and you watch somebody else being touched , you feel it in your phantom . EOS\n",
      "Viet: Thế nên , bạn có_một bệnh_nhân với một chiếc UKN ' ma . ' Nghĩa_là nếu cánh_tay thật đã bị cưa đi chỉ còn_lại ' bóng_ma ' cảm_giác , và bạn xem một ai đó bị chạm vào , bạn cũng cảm_thấy thế trong cánh_tay ' ma '\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Hatzalah actually started in Brooklyn by a UKN Jew years before us in UKN , and now it &apos;s all over the Jewish community in New York , even Australia and Mexico and many other Jewish communities . EOS\n",
      "Viet: Hatzalah thực_sự được bắt_đầu ở Brooklyn bởi một người Do Thái UKN vài năm trước chúng_tôi tại UKN , và bây_giờ nó là trên tất_cả cộng_đồng người Do Thái ở New_York , thậm_chí ở Úc , Mexico và nhiều các cộng_đồng người Do Thái khác nữa . EOS\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Now , I should tell you that I have no idea what UKN is , although at some point in my life , I dated a girl for two years who was getting her UKN in UKN . EOS\n",
      "Viet: Phải nói với các bạn rằng thật_ra tôi cũng không hiểu tâm_lý - vật_lý là cái gì , mặc_dù trong quá_khứ , tôi đã hẹn_hò trong_vòng 2 năm với một cô gái mà lúc_đó cô ấy cũng đang làm nghiên_cứu_sinh tiến_sĩ trong lĩnh_vực tâm_lý - vật_lý . EOS\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: UKN standards and confined masonry , where the building acts as a whole -- walls and columns and roofs and UKN tied together to support each other -- instead of breaking off into separate members and failing . EOS\n",
      "Viet: UKN chống động_đất cao , kĩ_thuật nề chặt_chẽ , tạo ra một toà nhà là một thể thống_nhất - - tường và cột mái và các thanh xà được gắn_kết chặt_chẽ để nâng_đỡ lẫn UKN , thay_vì vỡ thành từng mảng riêng_biệt và đổ sụp . EOS PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And it takes a school board member who is going to lobby for you and say , &quot; Know , the district is trying to impose this , but you have the freedom to do otherwise . &quot; EOS\n",
      "Viet: Và bước_tiến mới này đã khiến một thành_viên ban UKN nhà_trường người mà đang có ý_định \" vận_động hành_lang \" phát_biểu rằng , \" Bạn biết đấy , quận đang cố_gắng để UKN hoạt_động này , nhưng bạn có quyền tự_do thực_hiện nó . \" EOS PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: But to do that , if you have any amount of recline , it gets to the point where you need a headrest because nearly always , automatically hold your head in a vertical position , see ? EOS\n",
      "Viet: Nhưng để làm thế , nếu bạn ngả ra ở bất_cứ mức độ_nào nó cũng chạm tới điểm mà bạn phải cần tới một cái tựa đầu vì gần_như bạn luôn_luôn , tự_động giữ phần đầu , theo hướng thẳng_đứng , bạn thấy chứ ? EOS PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And we all pay UKN for solid waste costs , health problems associated with pollution and more UKN , the cost of UKN our young black and Latino men , who possess untold amounts of untapped potential . EOS\n",
      "Viet: Và chúng_ta đều phải trả_giá đắt cho chi_phí rác_thải , cũng như các vấn_đề sức_khoẻ liên_quan đến ô_nhiễm và đáng ghê_tởm hơn , chi_phí để bỏ_tù những thanh_niên da_đen và gốc Mĩ Latin , những người có rất nhiều khả_năng mà không được tận_dụng . EOS PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So I emailed him back and I said , &quot; Please share with me an image , something , that I can share with the whole PostSecret community and let everyone know your fairy tale ending . &quot; EOS\n",
      "Viet: Vậy_nên tôi email lại cho cậu ta và nói , \" Hãy chia_sẻ cho tôi một tấm hình , hay_là cái gì đó , mà tôi có_thể chia_sẻ với cả cộng_đồng PostSecret và cho mọi người thấy kết_thúc cổ_tích của các bạn . \" EOS PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: UKN Caroline Casey tells the story of her extraordinary life , starting with a revelation . In a talk that challenges perceptions , Casey asks us all to move beyond the limits we may think we have . EOS\n",
      "Viet: Nhà hoạt_động Caroline Casey kể câu_chuyện về cuộc_đời phi_thường của cô , bắt_đầu từ một bí_mật được tiết_lộ . Trong bài nói_chuyện thách_thức những nhận_thức này , Casey kêu_gọi tất_cả chúng_ta hãy vượt ra khỏi những giới_hạn mà chúng_ta tự đặt cho bản_thân . EOS PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So just think of this : you have a grid of neurons , and now you have a plane mechanical change in the position of the grid , and you get a UKN of your mental experience . EOS\n",
      "Viet: Và tôi nghĩ rằng : bạn có_một đường kẻ , một mạng_lưới các tế_bào thần_kinh , và giờ thì bạn có_một sự thay_đổi mặt_phẳng cơ_học về vị_trí của các đường kẻ , và bạn nhận thấy một sự UKN trong trải_nghiệm tinh_thần . EOS PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So you have a periphery and a center which contains about 75 percent of all the players , and in the center there &apos;s this tiny but dominant core which is made up of highly interconnected companies . EOS\n",
      "Viet: Ở đây , bạn có_một ngoại_vi và một trung_tâm chứa khoảng 75 % của tất_cả những người trong cuộc và ở trung_tâm bạn có một cái lõi bé xíu nhưng có vai_trò thống_trị được tạo_thành từ một cụm các công_ty kết_nối cao_cấp . EOS PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: What we call today Islamic Law , and especially Islamic culture -- and there are many Islamic cultures actually ; the one in Saudi Arabia is much different from where I come from in Istanbul or Turkey . EOS\n",
      "Viet: Điều mà chúng_ta gọi ngày_nay là luật Hồi_giáo , đặc_biệt là văn_hoá Hồi_giáo - - những nền văn_hoá rất đa_dạng và phong_phú nền văn_hoá ở Saudi Arabia có nhiều khác_biệt so_với nơi tôi sinh ra ở Istanbul hay Thổ Nhĩ Kỳ . EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And we could discuss that topic alone for days to really try to figure out , how is it that we hear something that &apos;s emotional from something that starts out as a vibration in the air ? EOS\n",
      "Viet: Và chúng_ta có_thể mất nhiều ngày bàn_luận về mỗi chủ_đề này thôi . để thực sự cố_gắng tìm_hiểu làm thế_nào chúng_ta có_thể nghe thấy một thứ gì đó cảm_động chỉ từ một thứ gì đó bắt_đầu là một rung_động trong không_gian ? EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: But you can have the exact opposite of all of those things -- respect , excitement , a broken Internet connection , UKN UKN -- and the thing still can go to hell in a hand basket . EOS\n",
      "Viet: Tuy_nhiên dù bạn có_thể có những điều trái_ngược chính_xác với trên đây - - sự tôn_trọng , thú_vị , kết_nối Internet bị hỏng , quan_hệ chỉ với chồng / vợ của mình - - thì mọi thứ vẫn có_thể trở_nên tệ_hại . EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Now if you consider the fact that nuclear weapons proliferation is associated with nuclear energy proliferation , because we know for example , India and Pakistan developed nuclear weapons secretly by UKN uranium in nuclear energy facilities . EOS\n",
      "Viet: Nào , nếu bạn coi bằng_chứng chứng_tỏ sự gia_tăng vũ_khí hạt_nhân liên_quan tới sự gia_tăng NL hạt_nhân , vì chúng_ta biết , UKN như , Ấn_Độ và Pakistan ngầm phát_triển vũ_khí hạt_nhân bằng cách làm_giàu uranium tại các cơ_sở NL hạt_nhân . EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And what we found was -- we UKN up the photographs so they couldn &apos;t recognize the before and after -- what we found was that the patients were regarded as being more attractive after the surgery . EOS\n",
      "Viet: Và điều mà chúng_tôi nhận thấy là - - chúng_tôi trộn các tấm hình lại với nhau để họ không_thể nhận ra trước và sau - - mà điều chúng_tôi nhận_ra là các bệnh_nhân cho_rằng mình đẹp hơn sau khi phẫu_thuật . EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We take ideas from other people , from people we &apos;ve learned from , from people we run into in the coffee shop , and we stitch them together into new forms and we create something new . EOS\n",
      "Viet: Chúng_ta lấy ý_tưởng từ người khác , học_hỏi từ họ , từ những người mà chúng_ta gặp ở quán cà_phê . và chúng_ta đan nó lại thành những hình_thể mới , và rồi chúng_ta tạo ra 1 cái gì đó mới_mẻ . EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: It could become a natural extension , that as well as buying stuff -- take it out of the Kindle -- you could buy books , music , real-life products , appliances and goods and so on . EOS\n",
      "Viet: Nó có_thể trở_thành một phần mở_rộng tự_nhiên , mà cũng tương_tự như việc mua_hàng - - mang nó ra khỏi các Kindle - bạn có_thể mua sách , âm_nhạc , sản_phẩm ngoài đời thật , các thiết_bị và sản_phẩm , vân_vân . EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: When they find a UKN or a bar , and it &apos;s not in the UKN , they &apos;re like , &quot; Ooh , this place must be cool ! It &apos;s not in the UKN . &quot; EOS\n",
      "Viet: Khi họ tìm thấy một câu_lạc_bộ đêm hay một quán bar mà nó lại không có trong cuốn hướng_dẫn , họ sẽ nghĩ , \" Ồ , nơi này chắc_chắn sẽ hay ho ! Nó không có trong cuốn hướng_dẫn . \" EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So what if I don &apos;t let people summarize individual TEDTalks to six words , but give them 10 TEDTalks at the same time and say , &quot; Please do a UKN summary for that one . &quot; EOS\n",
      "Viet: Chuyện gì sẽ xảy_ra nếu tôi không để mọi người tóm_tắt từng bài nói một bằng 6 từ , mà giao cho họ 10 bài nói TED cùng một_lúc và nói rằng \" Hãy làm bản tóm_tắt 6 từ cho chúng \" EOS PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Knowing that we &apos;re not going to put fifty of these in our UKN to store our power , we went to a group at University of Texas at Dallas , and we gave them this diagram . EOS\n",
      "Viet: Chúng_tôi hiểu rằng chúng_ta sẽ không chứa đến 50 cục pin này dưới tầng_hầm nhà mình để trữ năng_lượng , vì_thế chúng_tôi tìm đến một nhóm nghiên_cứu tại Đại_học Texas ở Dallas , và chúng_tôi đưa họ xem biểu_đồ này . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: It was covered in concrete to prevent UKN , and somehow we saw a sort of river in it , and we imagined this river to be a river in Japanese style with UKN UKN swimming upstream . EOS\n",
      "Viet: Nó được bao_bọc bởi bê_tông để phòng lở bùn , bằng cách nào đó , chúng_tôi thấy ở đó một con sông , chúng_tôi tưởng tưởng con_sông này sẽ là một con sông kiểu Nhật với UKN Nhật lội dòng . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And they did . Stories of change poured in from all over India , from UKN in the east , to UKN in the west , from UKN in the north , to UKN in the south . EOS\n",
      "Viet: Và chúng đã làm được . Những câu_chuyện về thay_đổi đổ về từ mọi vùng miền Ấn_Độ , từ UKN ở phía đông , tới UKN ở phía tây , từ UKN ở phía bắc tới UKN ở phía nam . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And as a consequence of that presumption , my hometown was burned to the ground by an invading army , an experience that has UKN many a Hungarian town and village throughout its long and troubled history . EOS\n",
      "Viet: Và như một hệ_quả của sự giả_định đó , quê_hương của tôi đã bị thiêu UKN bởi quân_đội xâm_lược , một trải_nghiệm đã xảy ra với rất nhiều làng_mạc và thị_trấn Hungary trong_suốt chiều_dài lịch_sử đầy biến_động của đất_nước này . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: UKN analysis of the speed of Owens &apos; joints shows that had been running on the same surface as Bolt , he wouldn &apos;t have been 14 feet behind , he would have been within one UKN . EOS\n",
      "Viet: UKN cơ_học của tốc_độ của các khớp_xương của Owens cho thấy anh ta đã chạy trên một bề_mặt giống_như Bolt , anh ta không_thể bị bỏ lại phía sau 14 feet , anh ta phải ở trong_khoảng 1 sải chân . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And it &apos;s like , everything single person , every single Mo UKN and Mo UKN that UKN in Movember is our celebrity ambassador , and that is so , so important and fundamental to our success . EOS\n",
      "Viet: Và như_thể là , mỗi một người , mỗi anh Mo , chị Mo tham_gia Movember đều là Đại_sứ nổi_tiếng của chúng_tôi , và điều đó là rất , rất quan_trọng và là điều cơ_bản để tạo nên thành_công_của chúng_tôi . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: A few years ago , the UKN Man was retired and replaced by this much less impressive specimen , who is a parody of American UKN , and that &apos;s what we have in our commercials today . EOS\n",
      "Viet: Một_vài năm về trước , nhân_vật Người đàn_ông UKN nghỉ_hưu và bị thay_thế bởi một chủng_loại người ít ấn_tượng hơn , nhại lại sự nam_tính kiểu Mỹ . Và đó là những gì chúng_ta thấy trong các đoạn quảng_cáo ngày_nay . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: If you can find a way to take the tribes that you &apos;re in and nudge them forward , along these tribal stages to what we call Stage Five , which is the top of the mountain . EOS\n",
      "Viet: Nếu bạn có_thể tìm được cách để dẫn_dắt bộ_lạc của mình và thúc_đẩy họ tiến lên phía trước , theo những giai_đoạn phát_triển bộ_lạc này cho_đến cái mà chúng_ta gọi là Giai_đoạn thứ_Năm , nằm trên đỉnh của sự phát_triển . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And linked to this crowd mania were examples all around the world -- from the election of a president to the infamous Wikipedia , and everything in between -- on what the power of numbers could achieve . EOS\n",
      "Viet: Và kết_nối với đám_đông điên_cuồng này là những ví_dụ trên toàn thế_giới - - từ sự bầu_cử tổng_thống cho_đến Wikipedia nổi_tiếng , và mọi thứ ở giữa - - về những gì mà sức_mạnh của những con_số có_thể đạt được . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We got rid of all the useless things like engines and UKN . We moved everything to the wheels , so you have the drive motor , the steering motor , the breaking all in the wheel . EOS\n",
      "Viet: Chúng_tôi đã loại_bỏ tất_cả những thứ vô_dụng như những động_cơ và bộ truyền_động . Chúng_tôi di_chuyển tất_cả mọi thứ_đến chỗ bánh_xe , Vì_vậy , bạn có động_cơ UKN , đông cơ lái , bộ phân UKN tất_cả trong chiếc bánh_xe . EOS PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So in that case , I have to design -- and we designed with Uri UKN and Tom UKN -- an enzyme wash to wash away , or strip , those UKN UKN with a specific enzyme . EOS\n",
      "Viet: Trong trường_hợp đó , tôi phải thiết_kế - - và chúng_tôi đã thiết_kế nó với Uri UKN và Tom UKN - - 1 enzim tẩy UKN tẩy sạch , hay loại_bỏ những kháng_nguyên UKN với các enzim xác_định này . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We live in a world shaped by food , and if we realize that , we can use food as a really powerful tool -- a conceptual tool , design tool , to shape the world differently . EOS\n",
      "Viet: Chúng_ta sống trong một thế_giới do thực_phẩm định_hình , và nếu ta nhận ra rằng , có_thể sử_dụng thực_phẩm như một công_cụ thực_sự quyền_năng - - một công_cụ khái_niệm , công_cụ thiết_kế , để định hình thế_giới khác đi . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We do have the technology that &apos;s UKN , and our network of global partners has been expanding and can be expanded at a rapid rate , so we &apos;re comfortable that this task can be accomplished . EOS\n",
      "Viet: Chúng_tôi có đủ kĩ_thuật cần_thiết có_thể đo đạt được , và mạng_lưới cộng_sự của chúng_tôi trên khắp thế_giới đang được mở_rộng và có_thể mở_rộng nữa với tốc_độ rất nhanh , vì_thế chúng_tôi tự_tin cho_rằng dự_án này có_thể được hoàn_thành . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: They UKN to their belief in the shining ideals of this country , and they proved that being an American is not just for some people , that race is not how we define being an American . EOS\n",
      "Viet: Họ bám vào niềm_tin về những lý_tưởng sáng_ngời của đất_nước này , và họ đã chứng_minh rằng việc được làm một người Mỹ không chỉ dành cho một_số người , rằng chủng_tộc không phải_cách mà chúng_ta định_nghĩa nên_người Mỹ . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We &apos;ve been using the technology to explore and to actually put out the first carbon UKN in high resolution in faraway places like the Amazon Basin and UKN places like the United States and Central America . EOS\n",
      "Viet: Chúng_tôi đã sử dụng công_nghệ này để khám pha ra và lập ra bản_đồ địa_lí cacbon đầu_tiên ở định_dạng cao tại những khu_vực xa như_là UKN sông Amazon và những khu_vực không xa lắm như_là Hoa Kì và UKN . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: But for many parts of Africa , a colleague of mine once put it this way , &quot; The cease-fire on Tuesday night was reached just in time for the genocide to start on Wednesday morning . &quot; EOS\n",
      "Viet: Nhưng đối_với nhiều nơi ở Châu Phi , một đồng_nghiệp của tôi đã một_lần nói theo cách này , \" Việc ngừng_bắn vào đêm Thứ_Ba đã đạt được vừa đúng thời_điểm để cuộc diệt_chủng bắt đầu_vào sáng thứ_Tư . \" EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And that is going to change our worldview in a profound way -- not in a UKN way as 400 years ago , Copernicus &apos; act did , by changing the way we view space and time . EOS\n",
      "Viet: Và điều đó sẽ thay_đổi nhận_thức về thế_giới của chúng_ta 1 cách sâu_sắc - không_phải theo 1 cách hoàn_toàn khác như 400 năm trước , Copernicus đã làm , bằng cách thay_đổi cách chúng_ta nhìn về không_gian và thời_gian . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I knew there were UKN men o &apos; war , all kinds of moon UKN , all kinds of things , but the box jellyfish from the southern oceans is not supposed to be in these waters . EOS\n",
      "Viet: tôi biết có những người Bồ_Đào Nha trong chiến_tranh , tất_cả các loại thạch mặt_trăng , tất_cả mọi thứ , nhưng loại sứa hộp từ đại_dương phía nam thì tôi không cho là sẽ có ở vùng nước này . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So to produce current , magnesium loses two electrons to become magnesium ion , which then UKN across the electrolyte , accepts two electrons from the UKN , and then mixes with it to form an UKN . EOS\n",
      "Viet: Để tạo ra dòng_điện , UKN mất đi 2 electron trở_thành ion magie , sau đó đi_qua chất điện_phân , nhận 2 electron từ UKN - ti - UKN , sau đó kết_hợp với nó hình_thành nên một UKN . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And that inspired me to create a day where we could recreate that feeling in cafeterias across the country : School Lunch UKN Day , a day where kids can make creative projects for their lunch staff . EOS\n",
      "Viet: Điều đó thôi_thúc tôi tổ_chức một ngày để mang_lại cảm_xúc đó một lần nữa tại nhà_ăn trên khắp_cả nước : \" UKN UKN UKN UKN \" , ngày các em học_sinh có_thể làm những dự_án sáng_tạo cho giáo_viên cấp_dưỡng . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And he knew from our work that if you go and do something very novel with somebody , you can drive up the dopamine in the brain , and perhaps trigger this brain system for romantic love . EOS\n",
      "Viet: Và anh ta biết từ nghiên_cứu của chúng_tôi rằng nếu bạn làm một điều gì đó mới_lạ với một người , bạn có_thể đẩy cao nồng_độ dopamine trong não . Và có_lẽ kích_hoạt phần não dành cho tình_yêu lãng_mạn . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: It was a simple trick , and I was just a script UKN back then , but to me , that trick , it felt like this , like I had discovered limitless potential at my fingertips . EOS\n",
      "Viet: Một thủ_thuật đơn_giản , và lúc đó tôi chỉ là một đứa nhóc tập viết code , nhưng với tôi , thủ_thuật đó , giống như thế này , như_thể khám_phá ra khả_năng vô_hạn từ các ngón_tay của mình . EOS PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: They had the compassion to be kind to themselves first and then to others , because , as it turns out , we can &apos;t practice compassion with other people if we can &apos;t treat ourselves kindly . EOS\n",
      "Viet: Họ có lòng thương_cảm để trở_nên tử_tế với chính họ trước và sau đó là với người khác , bởi_vì , hoá_ra là , chúng_ta không_thể thương_cảm người khác nếu chúng_ta không đối_xử với chính mình một_cách tử_tế . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: In fact , what we ought to do is take a page from their playbook , because the initiatives and programs that have been set in place for women in science and engineering and mathematics are fantastic . EOS\n",
      "Viet: Thực_tế , điều chúng_ta cần làm là lấy ra một trang từ quyến sách giải_trí của các em bởi các sáng_kiến và chương_trình đã được thực_hiện cho phụ_nữ trong lĩnh_vực khoa_học và kỹ_thuật và toán_học đều thật tuyệt_vời . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Now , the theory of mirror neurons simply says that in your brains , exactly now , as you watch me doing this , you are activating exactly the same neurons as if you do the actions . EOS\n",
      "Viet: Vâng , lý_thuyết neuron đối_chiếu nói một_cách đơn_giản rằng trong não bạn , chính_xác như bây_giờ , khi bạn thấy tôi làm thế này , bạn kích_hoạt đúng những neuron như tôi giống_như chính bạn đang làm vậy . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Charles Bonnet said , 250 years ago -- he wondered how , thinking these hallucinations , how , as he put it , the theater of the mind could be generated by the machinery of the brain . EOS\n",
      "Viet: Charles Bonnet nói rằng , 250 năm trước - - ông ấy tự_hỏi , về những ảo_giác này , như ông ấy đã viết , làm cách nào vở_kịch của trí_óc có_thể được tạo ra nhờ cơ_cấu bộ_não . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: There were weeds and piles of garbage and other stuff that I won &apos;t mention here , but she kept dragging me -- and lo and behold , at the end of that lot was the river . EOS\n",
      "Viet: đầy cỏ_dại và hàng_đống rác và những thứ khác mà tôi sẽ không nói đến ở đây , nhưng nó cứ kéo tôi đi - - - và cứ vậy đến cuối khu đó chính là dòng sông , EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And in a twist you would not believe in a Steven UKN film -- the UKN who was UKN this brutal beating was the very same UKN who had stolen socks from Mr. Teszler &apos;s UKN mill . EOS\n",
      "Viet: Và một nút thắt mà có_thể bạn không tin giống_như ở trong phim Steven UKN tên UKN giám_sát cuộc đánh_đập dã_man này rất giống với tên trộm đã lấy trộm những đôi tất từ nhà UKN của_ông Teszler . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Whether you sit down and eat a meal with your kids , whether you take your kids , or grandchildren , or nieces and nephews shopping to a farmers &apos; market . Just do UKN with them . EOS\n",
      "Viet: Bạn có ngồi xuống và ăn một bữa ăn với con bạn , bạn có đưa con của bạn , hoặc cháu , hoặc UKN họ đi UKN ra một chợ của nông_dân - chỉ_cần nếm với chúng . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And what we think in schizophrenia is there are genes of UKN , and whether this is one that UKN -- and then there &apos;s only a UKN of the population that &apos;s capable of being schizophrenic . EOS\n",
      "Viet: Chúng_tôi cho_rằng ở bệnh tâm_thần phân_liệt , có những gen gây ra bệnh này , và liệu đó có là nguyên_nhân gây_bệnh ... và chỉ có một phần nhỏ số người dân có khả_năng mắc bệnh tâm_thần phân_liệt . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And that &apos;s how it started . And that &apos;s how , really , it &apos;s unleashed , because suddenly people from Facebook , friends and others , just understand that they can be part of it . EOS\n",
      "Viet: Mọi việc đã bắt_đầu như_thế . Nó là như_thế , thật đấy , thả_lỏng , vì bỗng_dưng mọi người trên Facebook , bạn_bè và những người khác , hiểu rằng họ có_thể là một phần trong tấm áp_phích . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: UKN : That &apos;s coming out soon . I mean , the systems work , and we have to find out how to manufacture them and do things of this kind , but the basic technology works . EOS\n",
      "Viet: GW : Điều đó sẽ đến sớm thôi . Ý tôi là , hệ_thống làm_việc , và chúng_tôi cần tìm_ra cách làm_sao để làm_ra chúng và làm những việc loại này , nhưng công_nghệ cơ_bản thì hoạt_động được . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: A violinist , as we heard , who has done 10,000 hours of violin practice , some area that controls the movements of fingers in the brain change a lot , increasing UKN of the synaptic connections . EOS\n",
      "Viet: Một nghệ_sĩ violin , như chúng_ta biết , đã trải qua 10.000 giờ tập_luyện , một_số vùng trong não_bộ kiểm_soát những hoạt_động của các ngón_tay đã thay_đổi rất nhiều , tăng_cường sự củng_cố của những kết_nối khớp thần_kinh . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Joel is a New Yorker , and his studio for many years was in UKN , with a straight view downtown to the World Trade Center , and he photographed those buildings in every sort of light . EOS\n",
      "Viet: Joel đến từ New_York , và trong nhiều năm phòng chụp của anh được đặt ở UKN , với góc nhìn thẳng đến Trung_tâm Thương_mại Thế_giới , và anh chụp những toà nhà đó trong mọi loại ánh_sáng . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Now working memory capacity is our ability to leverage that , our ability to take what we know and what we can hang onto and leverage it in ways that allow us to satisfy our current goal . EOS\n",
      "Viet: Bây_giờ , khả_năng của trí_nhớ ngắn_hạn là khả_năng chúng_ta tận_dụng nó , khả_năng sử_dụng những gì chúng_ta biết và những gì chúng_ta có_thể nhớ và tận_dụng nó theo nhiều cách mà cho_phép chúng_ta thoả_mãn mục_tiêu hiện_tại của mình . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Move out , because as you change your world , as you change your community , as we believe that we are impacting one girl , one family , one village , one country at a time . EOS\n",
      "Viet: Hãy tiến_hành đi , bởi khi bạn thay_đổi thế_giới , bởi khi bạn thay_đổi cộng UKN , là khi chúng_ta tin rằng chúng_ta đang thay_đổi một bé gái , một gia_đình , một ngôi làng , một đất_nước . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Now , the most interesting implementation of that for us is when you can begin to have robotic walls , so your space can convert from exercise to a workplace , if you run a virtual company . EOS\n",
      "Viet: Bây_giờ , việc thực_hiện thú_vị nhất mà cho chúng_tôi khi bạn có_thể bắt_đầu có những bức tường robot , nên không_gian của bạn có_thể chuyển_đổi từ phòng tập_thể_dục thành nơi làm_việc , Nếu bạn điều_hành một công_ty ảo . EOS PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I came here tonight to tell you that things can be done , that you don &apos;t have always to be rich or powerful to get things on the way , that cities are a great challenge . EOS\n",
      "Viet: Tôi đến đây đêm nay để nói với các bạn là bạn có_thể làm được mọi thứ , rằng bạn không cần phải giàu_có hay quyền_lực để làm được_việc , rằng xây_dựng những thành_phố là một thử_thách . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So it &apos;s dealing with the fact that if you have AIDS , you also need to have nutrition rates , and the idea that the idea of nutrition is as important as getting UKN out there . EOS\n",
      "Viet: Như_vậy , nó đang giải_quyết vấn_đề rằng nếu bạn mắc_phải AIDS , bạn vẫn cần có_một tỉ_lệ dinh_dưỡng nhất_định , và ý_tưởng này - ý_tưởng về dinh_dưỡng - cũng quan_trọng không kém gì so_với việc phòng_chống virus UKN EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And as soon as I started this work , I received a UKN from the World Bank , from the legal department first , in which they said , &quot; You are not allowed to do this . EOS\n",
      "Viet: Và , ngay khi tôi bắt_đầu làm_việc đó , tôi nhận được một UKN từ Ngân_hàng Thế_giới , trước_tiên là từ ban UKN , trong đó , họ nói : \" Anh không được phép làm_việc này , EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Everyone can do it because three guys , Jon UKN , Matt Gray and Will UKN over at Google , saw the prototype of the UKN UKN , and they said , &quot; This is so fun . EOS\n",
      "Viet: Mọi người đều có_thể làm điều đó là nhờ ba người , Jon UKN , Matt Gray và Will UKN của Google nhìn_thấy bản_đồ mẫu của UKN UKN , và nói rằng \" Cái này thật hay ! EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And so right afterwards , I met backstage with Al , and with Lawrence UKN , who was there , and Laurie David , and Davis UKN , who was running documentaries for Participant at the time . EOS\n",
      "Viet: Và ngay sau buổi diễn_thuyết , tôi gặp AI sau hậu_trường và với Lawrence UKN , người đang ở đây , và Laurie David và Davis UKN , người đang làm tài_liệu cho Participant tại thời_điểm đó . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: It &apos;s based on the protesters at the Democratic Convention in 1968 , UKN Hoffman and crew , and , again , a story about a small group of individuals who did make change in the world . EOS\n",
      "Viet: Nó về những người biểu_tình ở UKN UKN vào năm 1968 , UKN Hoffman và các cộng_sự , Và một lần nữa , một câu_chuyện về một nhóm nhỏ các cá_nhân những người đã làm thay_đổi thế_giới . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And I think the West , at least some powers in the West , particularly the United States , made the mistake of supporting those secular dictators , thinking that they were more helpful for their interests . EOS\n",
      "Viet: Tôi nghĩ phương_Tây , ít nhất là một_số quyền_lực ở phương_Tây , đặc_biệt ở Hoa Kì , đã sai_lầm khi ủng_hộ những người phi tôn_giáo độc_tài đó , lầm tưởng họ sẽ giúp_đỡ vì lợi_ích của họ . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: In the same year , my mother disappeared one day , and then my sister told me that she was going to China to earn money , but that she would return with money and food soon . EOS\n",
      "Viet: Cũng trong năm đó , mẹ tôi biến mất UKN , và rồi chị tôi bảo với tôi là chị ấy sẽ đi Trung_Quốc để kiếm tiền , nhưng sẽ nhanh_chóng quay trở_lại với tiền và thức_ăn . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We run a project called the Bronx UKN UKN Training , which provides job training in the fields of ecological UKN , so that folks from our community have the skills to compete for these UKN jobs . EOS\n",
      "Viet: Chúng_tôi đã thực_hiện dự_án UKN Quản_Lý UKN Bronx , dự_án này sẽ đào_tạo trong các lĩnh_vực phục hồi sinh_thái , để người dân của cộng_đồng này có được các kĩ_năng cho các công_việc với thu_nhập cao . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So if you want to become famous early on , you should be an actor , because then fame starts rising by the end of your 20s -- you &apos;re still young , it &apos;s really great . EOS\n",
      "Viet: Vì_vậy nếu bạn muốn nổi_tiếng sớm , bạn nên làm diễn_viên , bởi tiếng_tăm của bạn sẽ ngày_càng tăng cuối những năm 20 của bạn - - bạn vẫn còn trẻ , điều đó thật UKN . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And even skin infection , which we originally thought wasn &apos;t that big a problem , mild skin infections naught to five give you a greatly increased chance of UKN failure , needing UKN at age 40 . EOS\n",
      "Viet: Kể_cả bệnh UKN , mà lúc đầu chúng_tôi nghĩ sẽ chẳng có vấn_đề gì , viêm da nhẹ từ 0 đến 5 tuổi làm giảm đáng_kể chức_năng thận , sẽ cần lọc máu ở tuổi 40 . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I think in another era we did not expect quite so much from ourselves , and it is important that we all remember that the next time we are staring with our hearts racing at those UKN . EOS\n",
      "Viet: Tôi nghĩ trong một thời_đại khác chúng_ta không đặt ra những yêu_cầu như_thế cho chính mình điều quan_trọng là chúng_ta đều nhớ rằng vào lần sau khi tim ta đập mạnh khi nhìn vào những giá_sách EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I &apos;ve found that finding out about what I &apos;m going to like in the future , my very best way is to talk to people who have actually done it much better than myself UKN it . EOS\n",
      "Viet: Tôi nhận ra rằng cách tốt nhất để phát_hiện ra tôi sẽ như thế_nào trong tương_lai là nói_chuyện với người khác những người đã làm điều đó tốt hơn nhiều là chỉ ngồi tưởng_tượng một_mình . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Yes , it does say that , but in a very specific context : the anticipated UKN of the sanctuary city of Mecca where fighting was usually forbidden , and the permission comes UKN about with UKN . EOS\n",
      "Viet: Kinh Koran có nhắc đến điều đó nhưng trong một bối_cảnh cụ_thể : đó là cuộc chinh_phục thánh_địa Mecca UKN nơi người_ta nghiêm_cấm các cuộc UKN , ẩu_đả , chỉ trừ_khi buộc phải làm thế . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I &apos;m already beyond the lifespan of most UKN , and the outcome of a mortal combat between me UKN stumbling around with a UKN spear and an UKN giant aurochs isn &apos;t very hard to predict . EOS\n",
      "Viet: Tôi đã thực_sự quá tuổi săn_bắn - hái_lượm , và kết_quả của một cuộc_chiến UKN giữa tôi UKN với một ngọn_giáo đá và một con bò rừng khổng_lồ đang UKN không phải là khó dự_đoán . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And the result is kind of a tree of life of these viruses , a UKN that looks very much like the type of life that we &apos;re used to , at least on the viral level . EOS\n",
      "Viet: Và kết quả_là sự phát_triển của đời_sống của những loại virus này , giống như sự phát_sinh loài . tương_tự như dạng sự sống mà chúng_ta đã biết , ít nhất là ở cấp_độ virus . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: If you just walk outside , there are trillions of dollars that have been invested in infrastructure around the world , putting up wires to get power from where it &apos;s created to where it &apos;s used . EOS\n",
      "Viet: Nếu các bạn bước ra ngoài , các bạn sẽ thấy hàng tỷ tỷ đô_la được đầu_từ khắp_nơi trên thế_giới để đặt đường_dây để lấy điện_từ nơi nó được sản_xuất cho đến_nơi nó được tiêu_dùng . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And by the way , one of the things that I did at that stage was , I had just arrived at the U.N. , and when I was there , there were UKN countries in the U.N. EOS\n",
      "Viet: Và nhân_tiện đây , một trong những điều tôi đã làm trong_suốt giai_đoạn đó là , khi tôi mới chuyển đến Liên_Hợp Quốc , và khi tôi ở đó , đã có UKN quốc_gia thành_viên . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Let &apos;s take baseball and pizza and compare it when talking about three aspects of sexual activity : the trigger for sexual activity , what happens during sexual activity , and the expected outcome of sexual activity . EOS\n",
      "Viet: Hãy lấy bóng chày và pizza để so_sánh khi nói về 3 khía_cạnh của sinh_hoạt tình_dục : khởi_điểm cho sinh_hoạt tình_dục , những gì diễn ra khi sinh_hoạt , và kết_quả mong_muốn của sinh_hoạt tình_dục , EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: If we want to better understand and decode diseases like cancer , we need to stop treating them as acute , isolated episodes , and consider and measure everything that affects our health on a permanent basis . EOS\n",
      "Viet: Nếu muốn hiểu rõ hơn và giải_mã các căn_bệnh như ung_thư , cần phải ngừng coi chúng là những bệnh cấp và cách_ly , và xem_xét , tính_toán mọi thứ có ảnh_hưởng lâu_dài đến sức_khoẻ . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I was told later , and also by lots of singers who were involved in this , that they sometimes recorded 50 or 60 different takes until they got just the right take -- they uploaded it . EOS\n",
      "Viet: Về sau này , tôi được biết , từ những người tham_gia phần này , rằng họ thu khoảng 50 hoặc 60 lần cho tới khi cảm_thấy đạt yêu_cầu - - họ mới đăng_tải . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: A little background : when my grade five was learning about child rights , they were made to roll incense sticks , UKN , for eight hours to experience what it means to be a child UKN . EOS\n",
      "Viet: Một_chút thông_tin nền : khi các học_sinh lớp 5 học về quyền trẻ_em , chúng phải cuốn hương , loại UKN trong 8 tiếng đồng_hồ . để trải_nghiệm làm lao_động trẻ_em là như thế_nào . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: This is UKN in UKN , who have recently launched the UKN UKN , a currency that you can only spend within the town , as a way of starting to cycle money within the local economy . EOS\n",
      "Viet: Ở UKN , UKN , người_ta gần_đây đã cho lưu_hành UKN UKN , 1 loại tiền_tệ chỉ được xài ở trong thành_phố đó , là 1 cách để lưu_chuyển tiền_bạc trong nền kinh_tế địa_phương . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Now , we don &apos;t have really any evidence of it , but I think , to give you a hypothesis , the best guess is that if you &apos;re left-handed , you &apos;re prone to schizophrenia . EOS\n",
      "Viet: Chúng_tôi chưa có bất_cứ bằng_chứng nào về điều đó , nhưng có_một giả_thiết , tôi nghĩ cách đoán biết hay nhất_là nếu bạn thuận tay_trái , thì bạn có xu_hướng mắc bệnh tâm_thần phân_liệt . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We all know quite a number of people who have everything that it would take to be happy , and they are not happy , because they want something else or they want more of the same . EOS\n",
      "Viet: Chúng_ta đều biết khá nhiều người có đầy_đủ mọi thứ có_thể đưa đến hạnh_phúc , nhưng họ lại không hạnh_phúc , bởi họ muốn một điều gì khác hoặc muốn có nhiều thêm nữa . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I wasn &apos;t really a rocket scientist , but I was working at the UKN UKN Laboratory in sunny California where it &apos;s warm ; whereas now I &apos;m in the UKN , and it &apos;s cold . EOS\n",
      "Viet: Tôi không thực_sự là kĩ_sư hàng_không vũ_trụ gian , nhưng tôi đang làm tại Phòng_thí_nghiệm UKN ở bang California đầy nắng ấm , nhưng giờ thì tôi ở vùng Tây UKN với thời_tiết lạnh . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: An attorney in the office who &apos;d never been interested in art , never visited the local art museum , dragged everyone she could from the building and got them outside to lie down underneath the sculpture . EOS\n",
      "Viet: Một luật_sư văn_phòng người chẳng bao_giờ quan_tâm đến nghệ_thuật , chưa_từng đến thăm quan viện bảo_tàng nghệ_thuật địa_phương , đã kéo tất_cả mọi người ở toà nhà và bảo họ nằm_xuống dưới tác_phẩm điêu_khắc . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And in the movie , they &apos;ve got a great scene in there where the word &quot; shoe &quot; is said , and a whole bunch of &apos; 50s and &apos; 60s shoes pop into my imagination . EOS\n",
      "Viet: Trong phim , họ có_một cảnh rất tuyệt , khi từ \" giầy \" được nói , thì một đống giầy thuộc những năm 50 và 60 xuất_hiện trong trí tưởng_tượng của tôi . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And as you get to the very bottom , you &apos;re faced with the unfortunate reality that if you don &apos;t save anything for retirement , you won &apos;t be able to afford any housing at all . EOS\n",
      "Viet: Và khi bạn xuống đến dưới cùng , bạn đối_mặt với một vấn_đề thật tệ_hại rằng bạn không_hề tiết_kiệm gì cho lúc nghỉ hưu , bạn không_thể chi_trả cho bất_cứ loại nhà_ở nào . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Often I hear , &quot; We are required to maximize returns , so we don &apos;t do that here , &quot; or , &quot; We don &apos;t want to use the portfolio to make policy statements . &quot; EOS\n",
      "Viet: Tôi thường nghe_nói \" Chúng_ta được yêu_cầu tối_đa hoá lợi_nhuận , do_đó chúng_ta không làm điều đó ở đây . \" hoặc \" chúng_ta không dùng danh_mục đầu_tư để lập báo_cáo chính_sách . \" EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: It &apos;s the only way to get our freedom back , and it &apos;s the only way to release the energy and passion needed so that we can meet the challenges of our time . Thank you . EOS\n",
      "Viet: Đó là cách duy_nhất lấy_lại sự tự_do của chúng_ta . Và đó là cách duy_nhất giải_phóng năng_lượng và niềm đa mê cần_thiết để chúng_ta có_thể đáp_ứng các thách_thức của thời_đại . Xin cảm_ơn . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We find that meditation allows your brain to get over the cultural ADHD that we &apos;ve been creating by trying to do multiple tasks at once and allows our brains to focus on the task at hand . EOS\n",
      "Viet: Hoạt_động ngồi_thiền cho_phép bộ_não vượt qua những trở_ngại ADHD cố_hữu mà chúng_ta đã tạo ra khi cố tìm cách thực_hiện nhiều việc cùng_lúc và cho phép bộ_não chỉ tập_trung vào một việc duy_nhất . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: This is , to me , the sound that UKN are supposed to be making when they &apos;re thinking really hard . It &apos;s this sound , it &apos;s like , the square root of five million . EOS\n",
      "Viet: Như_vậy , ta đã tạo ra được loại âm_thanh của máy_tính Với tôi , nó như kiểu đang UKN tính_toán . Căn bậc 2 của 5 000 000 = ? ? ? ? ? EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So it would work like this : If in a given year the government gave 0.2 percent of its income to overseas aid , the central bank would simply top it up with a further 0.2 percent . EOS\n",
      "Viet: Vì_vậy , nó sẽ hoạt_động như thế_này : Nếu trong năm mục_tiêu chính_phủ dành khoảng 0.2 % tổng_thu_nhập cho viện_trợ nước_ngoài , ngân_hàng trung_ương chỉ sẽ phải đơn_giản là gom_góp với hơn 0.2 % EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: But I believe it can be done in a way that protects our privacy , just like right now , when I look at your car from the outside , I don &apos;t really know about you . EOS\n",
      "Viet: Nhưng tôi tin ta sẽ có cách bảo_vệ sự riêng_tư cho mình , như bây_giờ , khi tôi nhìn xe bạn từ bên ngoài , tôi cũng không biết mấy lắm về bạn . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And the Cyrus cylinder comes back into public view and the text of this as a demonstration of why what is going to happen after the war is over in 1918 is part of a divine plan . EOS\n",
      "Viet: Và hình_trụ Cyrus lại xuất_hiện trong suy_nghĩ của công_chúng và văn_bản của nó như một minh_chứng tại_sao điều sẽ xảy_ra sau khi chiến_tranh kết_thúc năm 1918 là một phần của kế_hoạch thần_thánh . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: What is happening in the sky here is that there &apos;s a great big pattern of polarized light in the sky that you and I can &apos;t see . It &apos;s the way our eyes are built . EOS\n",
      "Viet: Điều đang diễn ra trên bầu_trời lúc_này đây là có một kiểu ánh_sáng phân_cực trên bầu_trời mà bạn và tôi không_thể thấy . Đó là cách mà mắt chúng_ta được cấu_tạo nên . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Local police departments can be governed by the city UKN , which can pass laws requiring the police to dispose of the data about innocent people while allowing the legitimate uses of the technology to go forward . EOS\n",
      "Viet: Hội_đồng thành_phố quản_lý sở cảnh_sát địa_phương , có_thể thông_qua luật yêu_cầu cảnh_sát loại_bỏ dữ_liệu của những người vô_tội đồng_thời , cho phép sử dụng công_nghệ trong phạm_vi hợp_pháp để tiến xa hơn . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Even though they look different on the outside , inside , they &apos;re all the same , and from time to time they would gather at a sacred cave deep inside the forest to celebrate their unity . EOS\n",
      "Viet: Dù chúng trông khác_nhau bề_ngoài , bên trong , chúng đều giống nhau cả , theo thời_gian chúng UKN lại tại một cái hang UKN trong rừng sâu để ăn_mừng sự đoàn_kết . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I have their date of birth , and their age , and what they did in their household , if they spoke English , and that &apos;s it . That &apos;s all I know of these people . EOS\n",
      "Viet: Tôi có ngày_sinh , tuổi của họ , và họ làm_gì trong nhà , họ có nói tiếng Anh không . Thế thôi . Đó là mọi thứ tôi biết về họ . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: If you design a city with the blind in mind , you design a city with a robust , accessible , UKN mass transit system that connects all parts of the city and the region all around . EOS\n",
      "Viet: Nếu bạn thiết_kế thành_phố với tâm_tưởng của người mù , bạn thiết_kế một thành_phố với một hệ_thống vận_tải thiết_thực và dễ kết_nối liên_kết tất_cả những phần của thành_phố và những khu_vực lân_cận . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Environmental justice , for those of you who may not be familiar with the term , goes something like this : no community should be UKN with more environmental UKN and less environmental benefits than any other . EOS\n",
      "Viet: Cho những người chưa biết đến thuật_ngữ này , công_bằng môi_trường có nghĩa là không một cộng_đồng nào phải chịu gánh_nặng môi_trường nhiều hơn và được hưởng lợi_ích môi_trường ít_hơn cộng_đồng khác . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I could imagine grandmothers being able to do UKN with their UKN , with their friends , and to be able to share all kinds of other activities around the house , like sharing a bedtime story . EOS\n",
      "Viet: Tôi có thể hình_dung các_bà có_thể chơi trò_chơi xã_hội với đám cháu gái và bạn_bè của chúng , và có_thể chia_sẻ tất_cả các hoạt_động khác_nhau quanh nhà , giống_như kể_chuyện đêm khuya . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: From user name UKN -- interesting user names we have here — &amp; amp ; quot ; UKN liberal moms making their sons gay . &amp; amp ; quot ; UKN , really ? Really ? Okay . EOS\n",
      "Viet: UKN có tên UKN cái tên thú_vị nhỉ \" UKN mẹ kinh_tởm đã biến con_trai mình thành người đồng_tính \" UKN à , thật chứ ? Thật vậy hả ? Được rồi . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: The differences are what interest me , because the one on the left was made to a pretty UKN design for about a million years -- from UKN million years ago to half a million years ago . EOS\n",
      "Viet: Điểm khác_biệt mới là cái tôi quan_tâm . Bởi_vì vật bên trái là 1 thiết_kế không thay_đổi trong_suốt khoản 1 triệu năm - - Từ 1,5 triệu năm_tới nửa triệu năm trước . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Behind that is the legal code , so if you want to very carefully construct it , and creative commons is taking off -- over 43 million things out there , licensed with a creative commons license . EOS\n",
      "Viet: Nó hợp_pháp , vì_vậy nếu bạn muốn xây_dựng nó một_cách rất cẩn_thận , và những sáng_tạo chung cất_cánh . Hơn 43 triệu sản_phẩm trên thế_giới , đăng_ký với bản_quyền sáng_tạo chung . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: But , one of the things that I was able to do in my design work is I could actually test run a piece of equipment in my mind , just like a virtual reality computer system . EOS\n",
      "Viet: Nhưng một trong những điều tôi có_thể làm trong việc thiết kế đó là tôi có_thể thử_nghiệm một thiết_bị trong trí_óc mình , giống như một hệ_thống máy_tính thế_giới thực_tế ảo . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And I believe that the Islamic modernism which began in the 19th century , but which had a UKN in the 20th century because of the political troubles of the Muslim world , is having a UKN . EOS\n",
      "Viet: Và tôi tin với sự hiện_đại hoá Hồi_giáo bắt_đầu từ thế_kỉ 19 , nhưng phải gây_dựng lại từ thế_kỉ 20 bởi những vấn_đề chính_trị ở thế_giới Hồi_giáo , đang được hồi_sinh . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: That seemed really like a crisis to me , that they had never been able to develop a vocabulary about escape , and about travel , and modernity in this trailer that was consistent with the shell . EOS\n",
      "Viet: Thật_là khủng_hoảng khi họ không bao_giờ có_thể phát_triển vốn từ về chạy_trốn , du_lịch và hiện_đại , trong toa xe móc này , các từ_vựng đó gắn_bó mật_thiết với phần vỏ . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So here was a room in which all the walls , floors , ceilings , pets , UKN plants , whatever was in there , were capable , not only of display but of sensing as well . EOS\n",
      "Viet: Vì_thế ở đây là một căn phòng nơi mà tường , sàn và trần , vật_nuôi , UKN hay bất_cứ cái_gì ở đó không chỉ có khả_năng hiển_thị mà_còn cảm_nhận được . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And to go back and to work with our mother is just what we saw in the civil war -- when I was 16 , and my sister was 11 , when the civil war broke out . EOS\n",
      "Viet: Và rồi trở_về làm_việc với mẹ chúng_tôi chỉ là_vì những gì chúng_tôi chứng_kiến trong cuộc nội_chiến - - khi tôi 16 tuổi , và em_gái 11 khi nội_chiến nổ ra . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: We tried to do the same thing by negotiating UKN deals with the soft drink and the snack food industry to cut the UKN and other dangerous content of food going to our children in the schools . EOS\n",
      "Viet: Chúng_tôi cố_gắng làm giống_như trước băng cách thương_lượng với ngành công_nghiệp nước_giải_khát và đồ ăn_vặt để cắt UKN và các chất nguy_hiểm khác khỏi đồ_ăn cho con_em chúng_ta ở trường . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: who was a murderer , and was a serial killer , had damage to their orbital cortex , which is right above the eyes , the orbits , and also the interior part of the temporal lobe . EOS\n",
      "Viet: những kẻ sát_nhân và giết_người hàng_loạt , đều có phần vỏ_não ở UKN bị tổn_thương . Phần ngay trên mắt , UKN , và cả phần trong của thuỳ thái_dương . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And to the degree that you can move in a healthy direction , you &apos;re going to live longer , you &apos;re going to feel better , you &apos;re going to lose weight , and so on . EOS\n",
      "Viet: Đến một mức_độ khi bạn đang trong hướng đi khoẻ_mạnh , bạn sẽ sống lâu hơn , cảm_thấy tốt hơn , bạn sẽ giảm cân , tương tự thế . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: But it is also time that we ended our denial and recognized that we &apos;re not acting , we &apos;re not close to acting and we &apos;re not going to act until this crisis hits the economy . EOS\n",
      "Viet: Nhưng giờ đã đến lúc để chúng_ta chấm_dứt sự phủ_nhận và nhận ra rằng chúng_ta thực_ra chưa làm_gì và sẽ không làm_gì cho tới khi khủng_hoảng ập_đến nền kinh_tế . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I believe that &apos;s true . If you make the effort to do the best of which you &apos;re capable , to try and improve the situation that exists for you , I think that &apos;s success . EOS\n",
      "Viet: Tôi tin điều này đúng . Nếu bạn nỗ_lực sử_dụng hết khả_năng của mình để cố_gắng cải_thiện tình_thế đặt ra trước_mắt bạn , tôi cho đó là thành_công . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Big data and algorithms are going to challenge white collar , professional knowledge work in the 21st century in the same way that factory automation and the assembly line challenged blue collar labor in the 20th century . EOS\n",
      "Viet: Dữ_liệu lớn và các thuật_toán sẽ thách_thức công_việc văn_phòng , công_việc chuyên_môn trong thế_kỷ 21 trong cùng một_cách mà máy_móc tự_động và dây_chuyền lắp_ráp thách_thức công_nhân ở thế_kỉ 20 EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: It &apos;s the belief that aliens are somehow more advanced than us , more moral than us , and the narratives always are that they &apos;re coming here to save us and rescue us from on high . EOS\n",
      "Viet: Đó là niềm_tin rằng người_ngoài hành_tinh tiên_tiến hơn chúng_ta , có đạo_đức hơn chúng_ta , Chuyện luôn_luôn là như thế_này họ từ trên kia xuống để cứu_vớt chúng_ta . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: A few years later , we then hit on the idea of explaining to people the secret of , how do you get the content you want , the way you want it and the easy way ? EOS\n",
      "Viet: Một_vài năm sau đó , chúng_tôi đã nghĩ ra được ý_tưởng diễn_giải với mọi người về bí_mật của phương_thức lấy_được nội_dung mong_muốn bằng một_cách dễ_dàng và tuỳ_ý ? EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So we took this kind of UKN idea and have worked really closely with Dr. Zullinger for the past year on writing this as a UKN curriculum offered at the high school level to the junior class . EOS\n",
      "Viet: Và chúng_tôi đã lấy ý_tưởng này và làm_việc với tiến_sĩ Zullinger trong năm vừa_qua viết nên một giáo_trình một năm ở trình_độ trung_học cho lớp 11 . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So I &apos;d like to show you the top four priorities which should be at least the first ones that we deal with when we talk about how we should deal with the problems in the world . EOS\n",
      "Viet: Giờ tôi muốn trình_bày về bốn ưu_tiên hàng_đầu những vấn_đề nên được giải_quyết đầu_tiên khi ta thảo_luận về cách đương_đầu với các vấn_đề của thế_giới . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Within South Africa , we &apos;ve got about 800 species of dung beetles , in Africa we &apos;ve got 2,000 species of dung beetles , and in the world we have about 6,000 species of dung beetles . EOS\n",
      "Viet: Chỉ riêng ở Nam Phi , chúng_ta có 80 loài bọ_hung , 2 000 loài ở châu Phi và 6 000 loài trên toàn thế_giới EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Now if you &apos;ve ever been out for a nice , peaceful walk by the lake and happened to see some ducks having sex , you &apos;ve undoubtedly been UKN , because it looks like gang rape . EOS\n",
      "Viet: Nếu bạn từng đi dạo_quanh bờ hồ và tình_cờ trông_thấy vịt giao_phối chắc_chắn bạn đã rất hoảng_hốt vì nó trông như hiếp_dâm tập_thể . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: Of course , there were lots of people who opted for a 100 percent one or the other , but I found that a much larger proportion of people identified as something that was much more nuanced . EOS\n",
      "Viet: Tất_nhiên cũng có nhiều người chọn 1 hay 100 phần_trăm , nhưng tôi thấy phần_đông người_ta xác_định bản_thân mình ở đâu_đó khác hơn . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: These are just plain old molecules , but if you sniff those molecules up these two little holes in the front of your face , you will have in your mind the distinct impression of a rose . EOS\n",
      "Viet: Đây là các phân_tử UKN , nhưng nếu dùng UKN đánh_hơi ta sẽ nhận_ra mùi không lẫn được_của hoa_hồng . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: And the problem of poor vision , is actually not just a health problem , it &apos;s also an educational problem , and it &apos;s an economic problem , and it &apos;s a quality of life problem . EOS\n",
      "Viet: Và thị_lực yếu không chỉ nguy_hại đến sức_khoẻ mà_còn ảnh_hưởng đến giáo_dục và kinh_tế , do_đó giảm_sút chất_lượng cuộc_sống . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: I &apos;m just going to give you a demo . By the way , I &apos;m just going to nerd out for just a few minutes here , so I would say , don &apos;t freak out . EOS\n",
      "Viet: Tôi sẽ bật cho các bạn một đoạn nghe thử . Tôi sẽ sử_dụng máy_tính trong vài phút . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "English: So this leads us to maybe think about , a little bit about , some of the models of science that we tend to use , and I &apos;d like to UKN you of some of them . EOS\n",
      "Viet: Vì điều này dẫn_dắt ta đến suy_nghĩ về một_số mô_hình khoa_học thông_thường mà ta không nên lạm_dụng . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    }
   ],
   "source": [
    "for t in zip(train_data_sample[1],train_data_sample[0]):\n",
    "    en_sent = []\n",
    "    vi_sent = []\n",
    "    for i in t[0]:\n",
    "        en_sent.append(en_lang.index2word[i.item()])\n",
    "    for i in t[1]:\n",
    "        vi_sent.append(vi_lang.index2word[i.item()])\n",
    "    print('English:',(' ').join(en_sent))\n",
    "    print('Viet:',(' ').join(vi_sent))\n",
    "    print('-*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14872"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17193"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OldEncoderRNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size,bi):\n",
    "#         super(OldEncoderRNN, self).__init__()\n",
    "#         self.bi=bi\n",
    "#         if self.bi:\n",
    "#             self.mul=2\n",
    "#         else:\n",
    "#             self.mul=1\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size,batch_first=True,bidirectional=self.bi)\n",
    "\n",
    "#     def forward(self, input, hidden):\n",
    "#         embedded = self.embedding(input)\n",
    "#         output = embedded\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "#         last_layer = output[:,-1,:self.hidden_size]\n",
    "#         first_layer = output[:,0,self.hidden_size:]\n",
    "#         hidden = torch.cat([first_layer,last_layer],dim=1).unsqueeze(0)\n",
    "#         return output, hidden\n",
    "\n",
    "#     def initHidden(self,bs):\n",
    "#         return torch.zeros(self.mul, bs, self.hidden_size).to(device)\n",
    "    \n",
    "    \n",
    "# class OldAttentionDecoderRNN(nn.Module):\n",
    "#     def __init__(self, hidden_size, output_size,bi, MAX_LEN,n_layers = 1, attention_type = None):\n",
    "#         super(OldAttentionDecoderRNN, self).__init__()\n",
    "#         self.mul=2\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "#         self.gru = nn.GRU(hidden_size*2 + hidden_size, hidden_size*2,batch_first=True, num_layers = n_layers)\n",
    "        \n",
    "#         self.attention_type = attention_type\n",
    "#         if self.attention_type is not None:\n",
    "#             self.attn = nn.Linear(self.hidden_size*2, self.hidden_size*2)\n",
    "#             self.attn_drop = nn.Dropout(p = 0.5)\n",
    "#         else:\n",
    "#             self.attn = nn.Linear(self.hidden_size * 2, MAX_LEN)\n",
    "        \n",
    "# #         self.attn_combine = nn.Linear(self.hidden_size * self.mul+self.hidden_size, self.hidden_size)\n",
    "        \n",
    "#         self.out = nn.Linear(self.mul*hidden_size, output_size)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input, hidden,encoder_outputs):\n",
    "#         bss = input.size(0)\n",
    "#         output = self.embedding(input)\n",
    "#         output = self.dropout(output)\n",
    "#         att_out = self.attn_drop(self.attn(hidden[-1])).unsqueeze(-1)\n",
    "#         if self.attention_type is not None:\n",
    "#             attn_wts = F.softmax(torch.bmm(encoder_outputs,att_out),dim = 1)\n",
    "#             attn_applied = torch.bmm(encoder_outputs.transpose(1,2),attn_wts).transpose(1,2)\n",
    "#         else:\n",
    "#             att_out = F.softmax(self.attn(cat),dim=1)\n",
    "#             attn_applied = torch.bmm(att_out,encoder_outputs)\n",
    "#         attn_cat = torch.cat((output, attn_applied), 2)\n",
    "#         output = F.relu(attn_cat)\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "#         output = self.out(output.squeeze(dim=1))\n",
    "#         output = self.softmax(output)\n",
    "\n",
    "#         return output, hidden\n",
    "\n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(self.mul, bs, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim, hidden_size,n_layers, rnn_type = 'lstm'):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = Embedding(input_size, embed_dim, PAD_IDX)\n",
    "        self.rnn_type =  rnn_type\n",
    "        self.dropout_in = nn.Dropout(p = 0.1)\n",
    "        self.n_layers = n_layers\n",
    "        if rnn_type == 'gru':\n",
    "            self.rnn = nn.GRU(embed_dim, hidden_size,batch_first=True,bidirectional=True, num_layers = self.n_layers, dropout = 0.1)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = LSTM(embed_dim, hidden_size, batch_first=True,bidirectional=True, num_layers = n_layers,dropout = 0.1)\n",
    "\n",
    "    def forward(self, input, src_len):\n",
    "        embedded = self.embedding(input)\n",
    "        bs = embedded.size(0)\n",
    "        output = self.dropout_in(embedded)\n",
    "#         print(\"encoded Input\", output.shape)\n",
    "#         output = torch.nn.utils.rnn.pack_padded_sequence(output, src_len, batch_first=True)\n",
    "        if self.rnn_type == 'gru':\n",
    "            hidden =  self.initHidden(bs)\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "#             output = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        elif self.rnn_type == 'lstm':\n",
    "            hidden, c = self.initHidden(bs)\n",
    "            output, (hiddden, c) = self.rnn(output,(hidden, c))\n",
    "        hidden = hidden.view(self.n_layers, 2, bs, -1).transpose(1, 2).contiguous().view(self.n_layers, bs, -1)\n",
    "        c = c.view(self.n_layers, 2, bs, -1).transpose(1, 2).contiguous().view(self.n_layers, bs, -1)\n",
    "#         print(output.shape)\n",
    "#         print(hidden.shape)\n",
    "#         print(c.shape)\n",
    "#             output = torch.nn.utils.rnn.pad_packed_sequence(output,batch_first=True)\n",
    "#         print(hidden.shape)\n",
    "#         print(\"rnn output\", output.shape)\n",
    "#         print(\"rnn hidden\", hidden.shape)\n",
    "#         hidden = hidden.transpose(0,1).contiguous().view(bs,-1)\n",
    "#         hidden_1 = torch.tanh(self.linear1(hidden)).unsqueeze(0)\n",
    "# #         print(\"rnn hidden_1\", hidden_1.shape)\n",
    "#         hidden_2 = torch.tanh(self.linear2(hidden)).unsqueeze(0)\n",
    "# #         print(\"rnn hidden_2\", hidden_2.shape)\n",
    "#         hidden = torch.cat([hidden_1,hidden_2],dim = 0)\n",
    "#         print(\"rnn hidden_final\", hidden.shape)\n",
    "#             print(hidden.shape)\n",
    "#         last_layer = output[:,-1,:self.hidden_size]\n",
    "#         first_layer = output[:,0,self.hidden_size:]\n",
    "#         hidden = first_layer + last_layer\n",
    "        return output, hidden, c\n",
    "\n",
    "    def initHidden(self,bs):\n",
    "        if self.rnn_type == 'gru' :\n",
    "            return torch.zeros(self.n_layers*2, bs, self.hidden_size).to(device)\n",
    "        elif self.rnn_type == 'lstm':\n",
    "            return torch.zeros(self.n_layers*2,bs,self.hidden_size).to(device),torch.zeros(self.n_layers*2,bs,self.hidden_size).to(device)\n",
    "\n",
    "class Attention_Module(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super(Attention_Module, self).__init__()\n",
    "        self.l1 = Linear(hidden_dim, output_dim, bias = False)\n",
    "        self.l2 = Linear(hidden_dim+output_dim, output_dim, bias =  False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outs, src_lens):\n",
    "        ''' hiddden: bsz x hidden_dim\n",
    "        encoder_outs: bsz x sq_len x encoder dim (output_dim)\n",
    "        src_lens: bsz\n",
    "        \n",
    "        x: bsz x output_dim\n",
    "        attn_score: bsz x sq_len'''\n",
    "        x = self.l1(hidden)\n",
    "        att_score = (encoder_outs.transpose(0,1) * x.unsqueeze(0)).sum(dim = 2)\n",
    "        seq_mask = sequence_mask(src_lens, max_len = max(src_lens).item()).transpose(0,1)\n",
    "        masked_att = seq_mask*att_score\n",
    "        masked_att[masked_att==0] = -1e10\n",
    "        attn_scores = F.softmax(masked_att, dim=0)\n",
    "        x = (attn_scores.unsqueeze(2) * encoder_outs.transpose(0,1)).sum(dim=0)\n",
    "        x = torch.tanh(self.l2(torch.cat((x, input), dim=1)))\n",
    "        return x, attn_scores\n",
    "        \n",
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, embed_dim, hidden_size, n_layers = 1, attention = False):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        encoder_output_size = hidden_size\n",
    "        self.embedding = Embedding(output_size, embed_dim, PAD_IDX)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.n_layers = n_layers\n",
    "        self.att_layer = Attention_Module(self.hidden_size, encoder_output_size) if attention else None\n",
    "        self.layers = nn.ModuleList([\n",
    "            LSTMCell(\n",
    "                input_size=self.hidden_size + embed_dim if layer == 0 else hidden_size,\n",
    "                hidden_size=hidden_size,\n",
    "            )\n",
    "            for layer in range(self.n_layers)\n",
    "        ])\n",
    "#         if self.rnn_type == 'gru':\n",
    "#             self.rnn = nn.GRU(self.hidden_size + embed_dim, hidden_size,batch_first=True, num_layers = self.n_layers, )\n",
    "#         elif self.rnn_type == 'lstm':\n",
    "#             self.rnn = nn.LSTM(self.hidden_size + embed_dim, hidden_size,batch_first=True, num_layers = self.n_layers)\n",
    "        self.fc_out = nn.Linear(self.hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, input,context_vector, prev_hiddens,prev_cs,encoder_outputs,src_len):\n",
    "        bsz = input.size(0)\n",
    "        output = self.embedding(input)\n",
    "        output = self.dropout(output)\n",
    "#         print(\"decoder Input embedded\", output.shape)\n",
    "        cated_input = torch.cat([output.squeeze(1),context_vector], dim = 1)\n",
    "#         print(\"cated_input\",cated_input.shape)\n",
    "        new_hiddens = []\n",
    "        new_cs = []\n",
    "        for i, rnn in enumerate(self.layers):\n",
    "            hidden, c = rnn(cated_input, (prev_hiddens[i], prev_cs[i]))\n",
    "            cated_input = self.dropout(hidden)\n",
    "            new_hiddens.append(hidden.unsqueeze(0))\n",
    "            new_cs.append(c.unsqueeze(0))\n",
    "        new_hiddens = torch.cat(new_hiddens, dim = 0)\n",
    "        new_cs = torch.cat(new_cs, dim = 0)\n",
    "\n",
    "        # apply attention using the last layer's hidden state\n",
    "        if self.att_layer is not None:\n",
    "            out, attn_score = self.att_layer(hidden, encoder_outputs, src_len)\n",
    "        else:\n",
    "            out = hidden\n",
    "            attn_score = None\n",
    "        out = self.dropout(out)\n",
    "        out_vocab = self.softmax(self.fc_out(out))\n",
    "\n",
    "        return out_vocab, out, new_hiddens, new_cs, attn_score\n",
    "    \n",
    "#     def initHidden(self,bs):\n",
    "#         if self.rnn_type == 'gru' :\n",
    "#             return None\n",
    "#         elif self.rnn_type == 'lstm':\n",
    "#             return torch.zeros(self.n_layers,bs,self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embedding(num_embeddings, embedding_dim, padding_idx):\n",
    "    m = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n",
    "    nn.init.uniform_(m.weight, -0.1, 0.1)\n",
    "    nn.init.constant_(m.weight[padding_idx], 0)\n",
    "    return m\n",
    "\n",
    "\n",
    "def LSTM(input_size, hidden_size, **kwargs):\n",
    "    m = nn.LSTM(input_size, hidden_size,**kwargs)\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "    return m\n",
    "\n",
    "\n",
    "def LSTMCell(input_size, hidden_size, **kwargs):\n",
    "    m = nn.LSTMCell(input_size, hidden_size,**kwargs)\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "    return m\n",
    "\n",
    "\n",
    "def Linear(in_features, out_features, bias=True, dropout=0):\n",
    "    \"\"\"Linear layer (input: N x T x C)\"\"\"\n",
    "    m = nn.Linear(in_features, out_features, bias=bias)\n",
    "    m.weight.data.uniform_(-0.1, 0.1)\n",
    "    if bias:\n",
    "        m.bias.data.uniform_(-0.1, 0.1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.max().item()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.arange(0, max_len).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).repeat([batch_size,1])\n",
    "    seq_range_expand = seq_range_expand.to(device)\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return (seq_range_expand < seq_length_expand).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_decode(encoder,decoder,data_en,data_de,src_len,tar_len,m_type,rand_num = 0.5):\n",
    "#     use_teacher_forcing = True if random.random() < rand_num else False\n",
    "# #     print(\"tar_len\",tar_len)\n",
    "#     bss = data_en.size(0)\n",
    "#     en_hid = encoder.initHidden(bss)\n",
    "#     en_out,en_hid = encoder(data_en, en_hid)\n",
    "#     max_tar_len_batch = max(tar_len).item()\n",
    "#     decoder_hidden = en_hid\n",
    "#     decoder_input = torch.tensor([[SOS_token]]*bss).to(device)\n",
    "# #     c = decoder.initHidden(bss)\n",
    "# #     print(\"max_tar_len_batch\",max_tar_len_batch)\n",
    "#     if use_teacher_forcing:\n",
    "#         d_out = []\n",
    "#         for i in range(max_tar_len_batch):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out)   \n",
    "#             else:\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             d_out.append(decoder_output.unsqueeze(-1))\n",
    "#             decoder_input = data_de[:,i].view(-1,1)\n",
    "#         d_hid = decoder_hidden\n",
    "#         d_out = torch.cat(d_out,dim=-1)\n",
    "#     else:\n",
    "#         d_out = []\n",
    "#         for i in range(max_tar_len_batch):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out)\n",
    "#             else:\n",
    "#                 decoder_output, decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             d_out.append(decoder_output.unsqueeze(-1))\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "# #             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             decoder_input = topi.squeeze().view(-1,1)\n",
    "#         d_hid = decoder_hidden\n",
    "#         d_out = torch.cat(d_out,dim=-1)\n",
    "#     return d_out, d_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_decode(encoder,decoder,data_en,data_de,src_len,tar_len,m_type,rand_num = 0.5):\n",
    "#     use_teacher_forcing = True if random.random() < rand_num else False\n",
    "# #     print(\"tar_len\",tar_len)\n",
    "#     bss = data_en.size(0)\n",
    "#     en_out,en_hid,c = encoder(data_en, src_len)\n",
    "#     max_tar_len_batch = max(tar_len).item()\n",
    "#     decoder_hidden = en_hid\n",
    "#     decoder_input = torch.tensor([[SOS_token]]*bss).to(device)\n",
    "# #     print(\"max_tar_len_batch\",max_tar_len_batch)\n",
    "#     if use_teacher_forcing:\n",
    "#         d_out = []\n",
    "#         for i in range(max_tar_len_batch):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden, c = decoder(decoder_input,decoder_hidden,en_out,src_len,c)   \n",
    "#             else:\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             d_out.append(decoder_output.unsqueeze(-1))\n",
    "#             decoder_input = data_de[:,i].view(-1,1)\n",
    "#         d_hid = decoder_hidden\n",
    "#         d_out = torch.cat(d_out,dim=-1)\n",
    "# #         print(\"softmax mat\", d_out.shape)\n",
    "#     else:\n",
    "#         d_out = []\n",
    "#         for i in range(max_tar_len_batch):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out,src_len,c)\n",
    "#             else:\n",
    "#                 decoder_output, decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             d_out.append(decoder_output.unsqueeze(-1))\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "# #             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             decoder_input = topi.squeeze().view(-1,1)\n",
    "#         d_hid = decoder_hidden\n",
    "#         d_out = torch.cat(d_out,dim=-1)\n",
    "#     return d_out, d_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_decode(encoder,decoder,data_en,data_de,src_len,tar_len,rand_num = 0.5):\n",
    "    use_teacher_forcing = True if random.random() < rand_num else False\n",
    "#     print(\"tar_len\",tar_len)\n",
    "    bss = data_en.size(0)\n",
    "    en_out,en_hid,en_c = encoder(data_en, src_len)\n",
    "    max_src_len_batch = max(src_len).item()\n",
    "    max_tar_len_batch = max(tar_len).item()\n",
    "    prev_hiddens = en_hid\n",
    "    prev_cs = en_c\n",
    "    decoder_input = torch.tensor([[SOS_token]]*bss).to(device)\n",
    "    prev_output = torch.zeros((bss, en_out.size(-1))).to(device)\n",
    "    if use_teacher_forcing:\n",
    "        d_out = []\n",
    "        for i in range(max_tar_len_batch):\n",
    "            out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                    prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                    src_len)\n",
    "            d_out.append(out_vocab.unsqueeze(-1))\n",
    "            decoder_input = data_de[:,i].view(-1,1)\n",
    "        d_out = torch.cat(d_out,dim=-1)\n",
    "#         print(\"softmax mat\", d_out.shape)\n",
    "    else:\n",
    "        d_out = []\n",
    "        for i in range(max_tar_len_batch):\n",
    "            out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                    prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                    src_len)\n",
    "            d_out.append(out_vocab.unsqueeze(-1))\n",
    "            topv, topi = out_vocab.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "            decoder_input = topi.squeeze().view(-1,1)\n",
    "        d_out = torch.cat(d_out,dim=-1)\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_cel_loss(input,target,nll):\n",
    "    input = input.transpose(1,2)\n",
    "    bs, sl = input.size()[:2]\n",
    "    return nll(input.contiguous().view(bs*sl,-1),target.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(encoder_optimizer,decoder_optimizer, encoder, decoder, loss_fun,m_type, dataloader, en_lang,\\\n",
    "                num_epochs=60, val_every = 1, train_bleu_every = 10,clip = 0.1):\n",
    "    best_score = 0\n",
    "    best_bleu = 0\n",
    "    loss_hist = {'train': [], 'validate': []}\n",
    "    bleu_hist = {'train': [], 'validate': []}\n",
    "    best_encoder_wts = None\n",
    "    best_decoder_wts = None\n",
    "    train_sorted = train.sort_values('en_len', ascending = False)\n",
    "    for epoch in range(num_epochs):\n",
    "        bs_dict = {'train':128,'validate':1, 'train_val':1}\n",
    "        train_used = shuffle_sorted_batches(train_sorted, bs_dict['train'])\n",
    "        # train_used = train.sample(5)\n",
    "        collate_fn_dict = {'train':vocab_collate_func, 'validate':vocab_collate_func_val, 'train_val':vocab_collate_func_val}\n",
    "        transformed_dataset = {'train': Vietnamese(train_used),\n",
    "                               'validate': Vietnamese(val, val = True),\n",
    "                               'train_val':Vietnamese(train.iloc[:50], val = True)\n",
    "                                                       }\n",
    "\n",
    "        dataloader = {x: DataLoader(transformed_dataset[x], batch_size=bs_dict[x], collate_fn=collate_fn_dict[x],\n",
    "                            shuffle=False, num_workers=0) for x in ['train', 'validate', 'train_val']}\n",
    "        for ex, phase in enumerate(['train']):\n",
    "            start = time.time()\n",
    "            total = 0\n",
    "            top1_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if phase == 'train':\n",
    "                encoder.train(True)\n",
    "                decoder.train(True)\n",
    "            else:\n",
    "                encoder.train(False)\n",
    "                decoder.train(False)\n",
    "            for data in dataloader[phase]:\n",
    "                encoder_optimizer.zero_grad()\n",
    "                decoder_optimizer.zero_grad()\n",
    "\n",
    "                encoder_i = data[0].to(device)\n",
    "                decoder_i = data[1].to(device)\n",
    "                src_len = data[2].to(device)\n",
    "                tar_len = data[3].to(device)\n",
    "#                 print(encoder_i.shape)\n",
    "                                \n",
    "                out = encode_decode(encoder,decoder,encoder_i,decoder_i,src_len,tar_len)\n",
    "                N = decoder_i.size(0)\n",
    "#                 out = out.view(-1,en_lang.n_words)\n",
    "#                 decoder_i = decoder_i.view(-1)\n",
    "                if loss_fun == 'masked_cel':\n",
    "                    loss = masked_cross_entropy(out.float(), decoder_i.long(), tar_len)\n",
    "                else:\n",
    "                    loss = flatten_cel_loss(out.float(), decoder_i.long(),loss_fun)\n",
    "#                 loss = loss_fun(out.float(), decoder_i.long())\n",
    "                running_loss += loss.item() * N\n",
    "                \n",
    "                total += N\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "                    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "                    encoder_optimizer.step()\n",
    "                    decoder_optimizer.step()\n",
    "            epoch_loss = running_loss / total\n",
    "            loss_hist[phase].append(epoch_loss)\n",
    "            print(\"epoch {} {} loss = {}, time = {}\".format(epoch, phase, epoch_loss,\n",
    "                                                                           time.time() - start))\n",
    "#             if epoch%train_bleu_every ==0:\n",
    "#                 train_loss, train_bleu_score = validation(encoder,decoder, dataloader['train'],loss_fun, en_lang,max_len,m_type)\n",
    "#                 bleu_hist['train'].append(train_bleu_score)\n",
    "#                 print(\"Train BLEU = \", train_bleu_score)\n",
    "            if epoch%val_every == 0:\n",
    "                val_bleu_score = validation_new(encoder,decoder, dataloader['validate'], en_lang, m_type)\n",
    "                bleu_hist['validate'].append(val_bleu_score)\n",
    "                print(\"validation BLEU = \", val_bleu_score)\n",
    "                if val_bleu_score > best_bleu:\n",
    "                    best_bleu = val_bleu_score\n",
    "                    best_encoder_wts = encoder.state_dict()\n",
    "                    best_decoder_wts = decoder.state_dict()\n",
    "            print('='*50)\n",
    "    encoder.load_state_dict(best_encoder_wts)\n",
    "    decoder.load_state_dict(best_decoder_wts)\n",
    "    print(\"Training completed. Best BLEU is {}\".format(best_bleu))\n",
    "    return encoder,decoder,loss_hist,bleu_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validation_new(encoder, decoder, val_dataloader, lang_en,m_type):\n",
    "#     encoder.train(False)\n",
    "#     decoder.train(False)\n",
    "#     pred_corpus = []\n",
    "#     true_corpus = []\n",
    "#     running_loss = 0\n",
    "#     running_total = 0\n",
    "#     bl = BLEU_SCORE()\n",
    "#     for data in val_dataloader:\n",
    "#         encoder_i = data[0].to(device)\n",
    "#         src_len = data[2].to(device)\n",
    "#         bs,sl = encoder_i.size()[:2]\n",
    "#         en_hid = encoder.initHidden(bs)\n",
    "#         en_out,en_hid = encoder(encoder_i, en_hid)\n",
    "#         decoder_hidden = en_hid\n",
    "#         decoder_input = torch.tensor([[SOS_token]]*bs).to(device)\n",
    "# #         c = decoder.initHidden(bs)\n",
    "#         d_out = []\n",
    "#         for i in range(sl+20):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out)\n",
    "#             else:\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             d_out.append(topi.item())\n",
    "#             if topi.item() == EOS_token:\n",
    "#                 break\n",
    "#         d_hid = decoder_hidden\n",
    "        \n",
    "#         true_corpus.append(data[-1])\n",
    "#         pred_sent = convert_id_list_2_sent(d_out,lang_en)\n",
    "#         pred_corpus.append(pred_sent)\n",
    "# #         print(\"True Sentence:\",data[-1])\n",
    "# #         print(\"Pred Sentence:\", pred_sent)\n",
    "# #         print('-*'*50)\n",
    "#     score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validation_new(encoder, decoder, val_dataloader, lang_en,m_type):\n",
    "#     encoder.train(False)\n",
    "#     decoder.train(False)\n",
    "#     pred_corpus = []\n",
    "#     true_corpus = []\n",
    "#     running_loss = 0\n",
    "#     running_total = 0\n",
    "#     bl = BLEU_SCORE()\n",
    "#     for data in val_dataloader:\n",
    "#         encoder_i = data[0].to(device)\n",
    "#         src_len = data[2].to(device)\n",
    "#         bs,sl = encoder_i.size()[:2]\n",
    "#         en_out,en_hid = encoder(encoder_i,src_len)\n",
    "#         decoder_hidden = en_hid\n",
    "#         decoder_input = torch.tensor([[SOS_token]]*bs).to(device)\n",
    "#         c = decoder.initHidden(bs)\n",
    "#         d_out = []\n",
    "#         for i in range(sl+20):\n",
    "#             if m_type==\"attention\":\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden,en_out,src_len,c)\n",
    "#             else:\n",
    "#                 decoder_output,decoder_hidden = decoder(decoder_input,decoder_hidden)\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "#             d_out.append(topi.item())\n",
    "#             if topi.item() == EOS_token:\n",
    "#                 break\n",
    "#         d_hid = decoder_hidden\n",
    "        \n",
    "#         true_corpus.append(data[-1])\n",
    "#         pred_sent = convert_id_list_2_sent(d_out,lang_en)\n",
    "#         pred_corpus.append(pred_sent)\n",
    "# #         print(\"True Sentence:\",data[-1])\n",
    "# #         print(\"Pred Sentence:\", pred_sent)\n",
    "# #         print('-*'*50)\n",
    "#     score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_new(encoder, decoder, val_dataloader, lang_en,m_type, verbose = False):\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "    pred_corpus = []\n",
    "    true_corpus = []\n",
    "    running_loss = 0\n",
    "    running_total = 0\n",
    "    bl = BLEU_SCORE()\n",
    "    for data in val_dataloader:\n",
    "        encoder_i = data[0].to(device)\n",
    "        src_len = data[2].to(device)\n",
    "        bs,sl = encoder_i.size()[:2]\n",
    "        en_out,en_hid,en_c = encoder(encoder_i,src_len)\n",
    "        max_src_len_batch = max(src_len).item()\n",
    "        prev_hiddens = en_hid\n",
    "        prev_cs = en_c\n",
    "        decoder_input = torch.tensor([[SOS_token]]*bs).to(device)\n",
    "        prev_output = torch.zeros((bs, en_out.size(-1))).to(device)\n",
    "        d_out = []\n",
    "        for i in range(sl+20):\n",
    "            out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                    prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                    src_len)\n",
    "            topv, topi = out_vocab.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "            d_out.append(topi.item())\n",
    "            decoder_input = topi.squeeze().view(-1,1)\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "        \n",
    "        true_corpus.append(data[-1])\n",
    "        pred_sent = convert_id_list_2_sent(d_out,lang_en)\n",
    "        pred_corpus.append(pred_sent)\n",
    "        if verbose:\n",
    "            print(\"True Sentence:\",data[-1])\n",
    "            print(\"Pred Sentence:\", pred_sent)\n",
    "            print('-*'*50)\n",
    "    score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_cross_entropy(logits, target, length):\n",
    "    logits = logits.transpose(1,2)\n",
    "#     print(\"logits\",logits.shape)\n",
    "#     print(\"target\",target.shape)\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.contiguous().view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "#     log_probs_flat = F.log_softmax(logits_flat, dim = 1)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "#     print(\"tar_flat\", target_flat.shape)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(logits_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask\n",
    "    loss = losses.sum() / length.float().sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'masked_cel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Old Interesting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(vi_lang.n_words,512,512, 2).to(device)\n",
    "decoder = AttentionDecoderRNN(en_lang.n_words,512,1024,n_layers=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# encoder = OldEncoderRNN(vi_lang.n_words,512,bi = True).to(device)\n",
    "# decoder = OldAttentionDecoderRNN(512,en_lang.n_words, True, MAX_LEN, attention_type='t2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss = 5.654132865225413, time = 341.1948525905609\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 1 train loss = 5.45065745284289, time = 341.9193711280823\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 2 train loss = 5.210996340336155, time = 342.40592312812805\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 4 train loss = 4.809566239472573, time = 341.6780881881714\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 5 train loss = 4.63142532622266, time = 341.56193590164185\n",
      "validation BLEU =  0.0\n",
      "==================================================\n",
      "epoch 6 train loss = 4.520703522670287, time = 341.8052592277527\n",
      "validation BLEU =  0.007257456178771249\n",
      "==================================================\n",
      "epoch 7 train loss = 4.4197971115632395, time = 341.1301064491272\n",
      "validation BLEU =  0.00778988176186667\n",
      "==================================================\n",
      "epoch 8 train loss = 4.318348191080374, time = 341.3023076057434\n",
      "validation BLEU =  0.00873574484162468\n",
      "==================================================\n",
      "epoch 9 train loss = 4.237790871660339, time = 341.7362952232361\n",
      "validation BLEU =  0.01489571311812371\n",
      "==================================================\n",
      "epoch 10 train loss = 4.151050939980724, time = 341.4068603515625\n",
      "validation BLEU =  0.019931957373692067\n",
      "==================================================\n",
      "epoch 11 train loss = 4.091922725855361, time = 341.15118384361267\n",
      "validation BLEU =  0.029661319317699324\n",
      "==================================================\n",
      "epoch 12 train loss = 3.9871769643770034, time = 341.45858216285706\n",
      "validation BLEU =  0.026448033178258345\n",
      "==================================================\n",
      "epoch 13 train loss = 3.913650239591969, time = 341.27526092529297\n",
      "validation BLEU =  0.03262531539161065\n",
      "==================================================\n",
      "epoch 14 train loss = 3.8498835832313856, time = 340.95101499557495\n",
      "validation BLEU =  0.044428241859491846\n",
      "==================================================\n",
      "epoch 15 train loss = 3.7791828754784245, time = 340.5919189453125\n",
      "validation BLEU =  0.03321728976507814\n",
      "==================================================\n",
      "epoch 16 train loss = 3.73131796845992, time = 341.2179868221283\n",
      "validation BLEU =  0.038820169262083856\n",
      "==================================================\n",
      "epoch 17 train loss = 3.690869427688029, time = 340.93681621551514\n",
      "validation BLEU =  0.05502212762362031\n",
      "==================================================\n",
      "epoch 18 train loss = 3.6422906667641395, time = 341.4393320083618\n",
      "validation BLEU =  0.058218193395599985\n",
      "==================================================\n",
      "epoch 19 train loss = 3.6025976965133, time = 342.0387489795685\n",
      "validation BLEU =  0.06265281052708205\n",
      "==================================================\n",
      "epoch 20 train loss = 3.568165948672502, time = 341.7699897289276\n",
      "validation BLEU =  0.06432711461627151\n",
      "==================================================\n",
      "epoch 21 train loss = 3.467597369658819, time = 341.9801962375641\n",
      "validation BLEU =  0.07283668274696219\n",
      "==================================================\n",
      "epoch 22 train loss = 3.4127586705564568, time = 341.50896525382996\n",
      "validation BLEU =  0.09124435261111917\n",
      "==================================================\n",
      "epoch 23 train loss = 4.11731507090061, time = 662.7810173034668\n",
      "validation BLEU =  3.7549343800802806\n",
      "==================================================\n",
      "epoch 24 train loss = 3.281447067662696, time = 341.5275800228119\n",
      "validation BLEU =  0.08469296828050618\n",
      "==================================================\n",
      "epoch 25 train loss = 3.271404259174648, time = 341.82329988479614\n",
      "validation BLEU =  0.15599388189696986\n",
      "==================================================\n",
      "epoch 26 train loss = 3.2869543531108163, time = 341.4335904121399\n",
      "validation BLEU =  0.1577493999531032\n",
      "==================================================\n",
      "epoch 27 train loss = 3.230972457758133, time = 341.5713469982147\n",
      "validation BLEU =  0.19278032635104744\n",
      "==================================================\n",
      "epoch 28 train loss = 3.19142589813571, time = 341.66050362586975\n",
      "validation BLEU =  0.1841768342892874\n",
      "==================================================\n",
      "epoch 29 train loss = 3.14125059641754, time = 341.6516077518463\n",
      "validation BLEU =  0.3033989533197111\n",
      "==================================================\n",
      "epoch 30 train loss = 3.115007367013696, time = 341.53219294548035\n",
      "validation BLEU =  0.3382457234701169\n",
      "==================================================\n",
      "epoch 31 train loss = 3.0665265867784455, time = 341.37299036979675\n",
      "validation BLEU =  0.5253105968823382\n",
      "==================================================\n",
      "epoch 32 train loss = 3.024415717351258, time = 342.05147337913513\n",
      "validation BLEU =  0.62985109085486\n",
      "==================================================\n",
      "epoch 33 train loss = 2.9992271762819116, time = 341.3521366119385\n",
      "validation BLEU =  0.7111174465433215\n",
      "==================================================\n",
      "epoch 34 train loss = 2.973018437561273, time = 341.3219199180603\n",
      "validation BLEU =  0.7373088348879125\n",
      "==================================================\n",
      "epoch 35 train loss = 2.9244212736258652, time = 341.13356590270996\n",
      "validation BLEU =  0.6783435354723314\n",
      "==================================================\n",
      "epoch 36 train loss = 2.887372524305964, time = 341.86699175834656\n",
      "validation BLEU =  0.7934873634499011\n",
      "==================================================\n",
      "epoch 37 train loss = 3.7282196400737244, time = 663.0309255123138\n",
      "validation BLEU =  5.422935553126234\n",
      "==================================================\n",
      "epoch 38 train loss = 2.7775619442239425, time = 341.5769703388214\n",
      "validation BLEU =  0.7515482635411938\n",
      "==================================================\n",
      "epoch 39 train loss = 2.822405433327482, time = 341.5337553024292\n",
      "validation BLEU =  0.8095145218786286\n",
      "==================================================\n",
      "epoch 40 train loss = 2.756222195607683, time = 341.53091645240784\n",
      "validation BLEU =  0.9110316293259347\n",
      "==================================================\n",
      "epoch 41 train loss = 2.721858608548948, time = 340.9498107433319\n",
      "validation BLEU =  0.918893890140245\n",
      "==================================================\n",
      "epoch 42 train loss = 2.7066624271356634, time = 341.8966417312622\n",
      "validation BLEU =  1.033976401522409\n",
      "==================================================\n",
      "epoch 43 train loss = 2.68261871081093, time = 341.18897104263306\n",
      "validation BLEU =  1.0486068458813393\n",
      "==================================================\n",
      "epoch 44 train loss = 3.5252452283543056, time = 662.3115556240082\n",
      "validation BLEU =  5.361300296846215\n",
      "==================================================\n",
      "epoch 45 train loss = 2.6183942231628192, time = 341.8273367881775\n",
      "validation BLEU =  1.0240641803494395\n",
      "==================================================\n",
      "epoch 46 train loss = 2.5875116109712106, time = 341.2915151119232\n",
      "validation BLEU =  1.3144701708752409\n",
      "==================================================\n",
      "epoch 47 train loss = 2.5632219784778774, time = 341.41440892219543\n",
      "validation BLEU =  1.3706422127766096\n",
      "==================================================\n",
      "epoch 48 train loss = 2.550861967960378, time = 341.4405016899109\n",
      "validation BLEU =  1.3821948611330461\n",
      "==================================================\n",
      "epoch 49 train loss = 3.414882306602232, time = 662.9478738307953\n",
      "validation BLEU =  5.737080525314268\n",
      "==================================================\n",
      "Training completed. Best BLEU is 5.737080525314268\n"
     ]
    }
   ],
   "source": [
    "enc, dec, loss_hist, acc_hist = train_model(encoder_optimizer, decoder_optimizer, encoder, decoder, criterion,\\\n",
    "                                            \"attention\", dataloader,en_lang, num_epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Sentence: Rachel Pike : The science behind a climate headline\n",
      "Pred Sentence: UKN UKN revolution .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .\n",
      "Pred Sentence: In four minutes , the UKN UKN UKN UKN UKN of of of the the the the the the the , , , , the the the , , , , , , , , , , the the the the the the the the the the the\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
      "Pred Sentence: I want you to know about the great challenges of the challenges that you &apos;ve been to to .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .\n",
      "Pred Sentence: These are things like like like to look to the , , , , , , , , , UKN UKN UKN\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: They are both two branches of the same field of atmospheric science .\n",
      "Pred Sentence: Both are both UKN of a of a of . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .\n",
      "Pred Sentence: The recent headlines like this as the UKN UKN UKN , which if they UKN the UKN to the the the the\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: That report was written by 620 scientists from 40 countries .\n",
      "Pred Sentence: UKN was written by the UKN UKN UKN UKN .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: They wrote almost a thousand pages on the topic .\n",
      "Pred Sentence: They wrote a thousand pages on this video .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .\n",
      "Pred Sentence: And all all of are by by by by UKN of of UKN UKN and .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: It &apos;s a big community . It &apos;s such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .\n",
      "Pred Sentence: It &apos;s a huge community , and , , , , the the the the the the the the the the the the the the the . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Over 15,000 scientists go to San Francisco every year for that .\n",
      "Pred Sentence: More , we invited to San Francisco at San Francisco .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And every one of those scientists is in a research group , and every research group studies a wide variety of topics .\n",
      "Pred Sentence: Every human group is a group group , a group of students , and each of them .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: For us at Cambridge , it &apos;s as varied as the El Niño oscillation , which affects weather and climate , to the assimilation of satellite data , to emissions from crops that produce biofuels , which is what I happen to study .\n",
      "Pred Sentence: For us , , , , the the the the of of of of , , , , , , , , , , , , , , , , , , , , , , , , the the the the the the . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And in each one of these research areas , of which there are even more , there are PhD students , like me , and we study incredibly narrow topics , things as narrow as a few processes or a few molecules .\n",
      "Pred Sentence: Each of these projects projects more , , , , , , , , , , , I , , , , , , , , , , , , some some . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And one of the molecules I study is called isoprene , which is here . It &apos;s a small organic molecule . You &apos;ve probably never heard of it .\n",
      "Pred Sentence: One of the UKN of this is called called UKN . UKN . It &apos;s a . a . a , , , , you . . . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: The weight of a paper clip is approximately equal to 900 zeta-illion -- 10 to the 21st -- molecules of isoprene .\n",
      "Pred Sentence: A little of UKN UKN UKN UKN UKN UKN UKN -- -- -- -- -- -- -- -- .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: But despite its very small weight , enough of it is emitted into the atmosphere every year to equal the weight of all the people on the planet .\n",
      "Pred Sentence: UKN small , very small , but the amount of energy is actually in the atmosphere of the the of .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: It &apos;s a huge amount of stuff . It &apos;s equal to the weight of methane .\n",
      "Pred Sentence: It &apos;s a huge amount of carbon emissions .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And because it &apos;s so much stuff , it &apos;s really important for the atmospheric system .\n",
      "Pred Sentence: It &apos;s because huge huge huge amount of water , it &apos;s important .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Because it &apos;s important to the atmospheric system , we go to all lengths to study this thing .\n",
      "Pred Sentence: It &apos;s because it &apos;s because the environment , the system that we &apos;re going to to the we the the .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We blow it up and look at the pieces .\n",
      "Pred Sentence: We made it and and and we a little . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: This is the EUPHORE Smog Chamber in Spain .\n",
      "Pred Sentence: This is UKN UKN UKN in Spain .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Atmospheric explosions , or full combustion , takes about 15,000 times longer than what happens in your car .\n",
      "Pred Sentence: UKN explosions , UKN UKN UKN , UKN times times times the of of\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: But still , we look at the pieces .\n",
      "Pred Sentence: And sometimes we &apos;re still small .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We run enormous models on supercomputers ; this is what I happen to do .\n",
      "Pred Sentence: We created the models model on computers .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: Our models have hundreds of thousands of grid boxes calculating hundreds of variables each , on minute timescales .\n",
      "Pred Sentence: Our data has thousands of thousands of UKN UKN UKN hundreds of hundreds of .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Sentence: And it takes weeks to perform our integrations .\n",
      "Pred Sentence: It &apos;s takes a week of weeks .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And we perform dozens of integrations in order to understand what &apos;s happening .\n",
      "Pred Sentence: We need hundreds of these kinds of algorithms to do that .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We also fly all over the world looking for this thing .\n",
      "Pred Sentence: We &apos;re around around the world to to .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: I recently joined a field campaign in Malaysia . There are others .\n",
      "Pred Sentence: I recently joined a UKN in the UKN . . . . . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We found a global atmospheric watchtower there , in the middle of the rainforest , and hung hundreds of thousands of dollars worth of scientific equipment off this tower , to look for isoprene , and of course , other things while we were there .\n",
      "Pred Sentence: We found a global atmospheric global in the , , , and and and and we and to to to thousands thousands thousands of thousands of , , , , , , , , , , and , . . . . . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: This is the tower in the middle of the rainforest , from above .\n",
      "Pred Sentence: This is the UKN UKN in the middle of the the .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And this is the tower from below .\n",
      "Pred Sentence: \n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And on part of that field campaign we even brought an aircraft with us .\n",
      "Pred Sentence: We have we we we .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And this plane , the model , BA146 , which was run by FAAM , normally flies 120 to 130 people .\n",
      "Pred Sentence: This slide , UKN , UKN , which is UKN UKN , UKN UKN .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: So maybe you took a similar aircraft to get here today .\n",
      "Pred Sentence: Very probably you have on a new future .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: But we didn &apos;t just fly it . We were flying at 100 meters above the top of the canopy to measure this molecule -- incredibly dangerous stuff .\n",
      "Pred Sentence: We didn &apos;t fly just how fast it was to fly to the fly to the surface of the surface of the reef , and it &apos;s very pretty cheap .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We have to fly at a special incline in order to make the measurements .\n",
      "Pred Sentence: We have to UKN UKN UKN UKN ,\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We hire military and test pilots to do the maneuvering .\n",
      "Pred Sentence: We hire military and pilots to choose the police .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We have to get special flight clearance .\n",
      "Pred Sentence: UKN to .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And as you come around the banks in these valleys , the forces can get up to two Gs .\n",
      "Pred Sentence: When you go around the the the Valley Valley , the , the , that are .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And the scientists have to be completely harnessed in in order to make measurements while they &apos;re on board .\n",
      "Pred Sentence: UKN have been to to to to to to to to to to .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: So , as you can imagine , the inside of this aircraft doesn &apos;t look like any plane you would take on vacation .\n",
      "Pred Sentence: So you can imagine , in the way , the right thing is not going to be any any any .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: It &apos;s a flying laboratory that we took to make measurements in the region of this molecule .\n",
      "Pred Sentence: It &apos;s a laboratory laboratory that we can try to do .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: We do all of this to understand the chemistry of one molecule .\n",
      "Pred Sentence: We do it to to to to the molecular molecular molecule .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And when one student like me has some sort of inclination or understanding about that molecule , they write one scientific paper on the subject .\n",
      "Pred Sentence: When my dad was a a a about or or or , , , , , , , , a a . a . . .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And out of that field campaign we &apos;ll probably get a few dozen papers on a few dozen processes or molecules .\n",
      "Pred Sentence: And the results of that that we have able to a a a a a a of of\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And as a body of knowledge builds up , it will form one subsection , or one sub-subsection of an assessment like the IPCC , although we have others .\n",
      "Pred Sentence: When a of of of this it it it , , a a , , a a a a or or or , , , , , ,\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: And each one of the 11 chapters of the IPCC has six to ten subsections .\n",
      "Pred Sentence: Every single chapter of the UKN of the IPCC has about 10 words .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "True Sentence: So you can imagine the scale of the effort .\n",
      "Pred Sentence: So you can see how this great movement of this work is going to be .\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.89490079655882"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_new(enc,dec,dataloader['train_val'],en_lang, 'attention', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second with shuffled batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(vi_lang.n_words,512,512, 2).to(device)\n",
    "decoder = AttentionDecoderRNN(en_lang.n_words,512,1024,n_layers=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = OldEncoderRNN(vi_lang.n_words,512,bi = True).to(device)\n",
    "# decoder = OldAttentionDecoderRNN(512,en_lang.n_words, True, MAX_LEN, attention_type='t2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss = 3.7870543791730453, time = 384.6493935585022\n",
      "validation BLEU =  3.3420959969798782\n",
      "==================================================\n",
      "epoch 1 train loss = 3.6821328162381555, time = 375.25617361068726\n",
      "validation BLEU =  3.2399475776495463\n",
      "==================================================\n",
      "epoch 2 train loss = 3.759972292985075, time = 423.8116104602814\n",
      "validation BLEU =  3.353920422385696\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "enc, dec, loss_hist, acc_hist = train_model(encoder_optimizer, decoder_optimizer, encoder, decoder, criterion,\\\n",
    "                                            \"attention\", dataloader,en_lang, num_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_new(enc,dec,dataloader['train_val'],en_lang, 'attention', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
